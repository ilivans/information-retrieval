Information-theoretic lower bounds for convex optimization with erroneous oracles

Yaron Singer Harvard University Cambridge, MA 02138 yaron@seas.harvard.edu

Jan Vondrak IBM Almaden Research Center
San Jose, CA 95120 jvondrak@us.ibm.com

Abstract
We consider the problem of optimizing convex and concave functions with access to an erroneous zeroth-order oracle. In particular, for a given function x  f (x) we consider optimization when one is given access to absolute error oracles that return values in [f (x) - , f (x) + ] or relative error oracles that return value in [(1 - )f (x), (1 + )f (x)], for some > 0. We show stark information theoretic impossibility results for minimizing convex functions and maximizing concave functions over polytopes in this model.
1 Introduction
Consider the problem of minimizing a convex function over some convex domain. It is well known that this problem is solvable in the sense that there are algorithms which make polynomially-many calls to an oracle that evaluates the function at every given point, and return a point which is arbitrarily close to the true minimum of the function. But suppose that instead of the true value of the function, the oracle has some small error. Would it still be possible to optimize the function efficiently? To formalize the notion of error, we can consider two types of erroneous oracles:
* For a given function f : [0, 1]n  [0, 1] we say that f : [0, 1]n  [0, 1] is an absolute -erroneous oracle if x  [0, 1]n we have that: f (x) = f (x) + x where x  [- , ].
* For a given function f : [0, 1]n  R we say that f : [0, 1]n  R is a relative -erroneous oracle if x  [0, 1]n we have that: f (x) = xf (x) where x  [1 - , 1 + ].
Note that we intentionally do not make distributional assumptions about the errors. This is in contrast to noise, where the errors are assumed to be random and independently generated from some distribution. In such cases, under reasonable conditions on the distribution, one can obtain arbitrarily good approximations of the true function value by averaging polynomially many points in some -ball around the point of interest. Stated in terms of noise, in this paper we consider oracles that have some small adversarial noise, and wish to understand whether desirable optimization guarantees are obtainable. To avoid ambiguity, we refrain from using the term noise altogether, and refer to such as inaccuracies in evaluation as error.
While distributional i.i.d. assumptions are often reasonable models, evaluating our dependency on these assumptions seems necessary. From a practical perspective, there are cases in which noise can be correlated, or where the data we use to estimate the function is corrupted in some arbitrary way. Furthermore, since we often optimize over functions that we learn from data, the process of fitting a model to a function may also introduce some bias that does not necessarily vanish, or may vanish. But more generally, it seems like we should morally know the consequences that modest inaccuracies may have.
1

f(x)
x
Figure 1: An illustration of an erroneous oracle to a convex function that fools a gradient descent algorithm.
Benign cases. In the special case of a linear function f (x) = c x, for some c  Rn, a relative -error has little effect on the optimization. By querying f (ei), for every i  [n] we can extract ci  [(1- )ci, (1+ )ci] and then optimize over f (x) = c x. This results in a (1 )-multiplicative approximation. Alternatively, if the erroneous oracle f happens to be a convex function, optimizing f(x) directly retains desirable optimization guarantees, up to either additive and multiplicative errors. We are therefore interested in scenarios where the error does not necessarily have nice properties.
Gradient descent fails with error. For a simple example, consider the function illustrated in Figure 1. The figure illustrates a convex function (depicted in blue) and an erroneous version of it (dotted red), s.t. on every point, the oracle is at most some additive > 0 away from the true function value (the margins of the function are depicted in grey). If we assume that a gradient descent algorithm is given access to the erroneous version (dotted red) instead of the true function (blue), the algorithm will be trapped in a local minimum that can be arbitrarily far from the true minimum. But the fact that a naive gradient descent algorithm fails does not necessarily mean that there isn't an algorithm that can overcome small errors. This narrates the main question in this paper.
Is convex optimization robust to error?
Main Results. Our results are largely spoilers. We present stark information-theoretic lower bounds for both relative and absolute -erroneous oracles, for any constant and even sub-constant
> 0. In particular, we show that:
* For minimizing a convex function (or maximizing a concave function) f : [0, 1]n  [0, 1] over [0, 1]n: we show that for any fixed  > 0, no algorithm can achieve an additive approximation within 1/2 -  of the optimum, using a subexponential number of calls to an absolute n-1/2+-erroneous oracle.
* For minimizing a convex function f : [0, 1]n  [0, 1] over a polytope P  [0, 1]n: for any fixed > 0, no algorithm can achieve a finite multiplicative factor using a subexponential number of calls to a relative -erroneous oracle.
* For maximizing a concave function f : [0, 1]n  [0, 1] over a polytope P  [0, 1]n: for any fixed > 0, no algorithm can achieve a multiplicative factor better than (n-1/2+ ) using a subexponential number of calls to a relative -erroneous oracle;
* For maximizing a concave function f : [0, 1]n  [0, 1] over [0, 1]n: for any fixed > 0, no algorithm can obtain a multiplicative factor better than 1/2 + using a subexponential number of calls to a relative -erroneous oracle. (And there is a trivial 1/2-approximation without asking any queries.)
Somewhat surprisingly, many of the impossibility results listed above are shown for a class of extremely simple convex and concave functions, namely, affine functions: f (x) = c x + b. This is
2

in sharp contrast to the case of linear functions (without the constant term b) with relative erroneous oracles as discussed above. In addition, we note that our results extend to strongly convex functions.

1.1 Related work

The oracle models we study here fall in the category of zeroth-order or derivative free. Derivativefree methods have a rich history in convex optimization and were among the earliest to numerically solve unconstrained optimization problems. Recently these approaches have enjoyed increasing interest, as they are useful in scenarios where black-box access is given to the function or cases in which gradient information is difficult to compute or does not exist [9, 8, 11, 15, 14, 6]

There has been a rich line of work for noisy oracles, where the oracles return some erroneous version of the function value which is random. In a stochastic framework, these settings correspond to repeatedly choosing points in some convex domain, obtaining noisy realizations of some underlying convex function's value. Most frequently, the assumption is that one is given a first-order noisy oracle with some assumptions about the distribution that generates the error [13, 12]. In the learning theory community, optimization with stochastic noisy oracles is often motivated by multi-armed bandits settings [4, 1], and regret minimization with zeroth-order feedback [2]. All these models consider the case in which the error is drawn from a distribution.

The model of adversarial noise in zeroth order oracles has been mentioned in [10] which considers a related model of erroneous oracles and informally argues that exponentially many queries are required to approximately minimize a convex function in this model (under an 2-ball constraint).

In recent work, Belloni et al. [3] study convex optimization with erroneous oracles. Interestingly,

Belloni et al. show positive results. In their work they develop a novel algorithm that is based on

sampling from an approximately log-concave distribution using the Hit-and-Run method and show

that their method has polynomial query complexity. In contrast to the negative results we show in

this work, the work of Belloni et al. assumes the (absolute) erroneous oracle returns f (x) + x

with x  [- n , n ]. That is, the error is not a constant term, but rather is inversely proportional

to the dimension. Our lower bounds for additive approximation hold when the oracle error is not

necessarily

a

constant

but

x



[1
n1/2-

,

1 n1/2-

]

for

a

constant

0

<



<

1/2.

2 Preliminaries

Optimization and convexity. For a minimization problem, given a nonnegative objective function f and a polytope P we will say that an algorithm provides a (multiplicative) -approximation ( > 1) if it finds a point x  P s.t. f (x)   minxP f (x). For a maximization problem, an algorithm provides an -approximation ( < 1) if it finds a point x s.t. f (x)   maxxP f (x).
For absolute erroneous oracles, given an objective function f and a polytope P we will aim to find a point x  P which is within an additive error of  from the optimum, with  as small as possible. That is, for a  > 0 we aim to find a point x s.t. |f (x)-minx f (x)| <  in the case of minimization.
A function f : P  R is convex on P if f (tx + (1 - t)y)  tf (x) + (1 - t)f (y) (or concave if f (tx + (1 - t)y)  tf (x) + (1 - t)f (y)) for every x, y  P and t  [0, 1].

Chernoff bounds. Throughout the paper we appeal to the Chernoff bounds. We note that while typically stated for independent random variables X1, . . . , Xm, Chernoff bounds also hold for negatively associated random variables.

Definition 2.1 ([5], Definition 1). Random variables X1, . . . , Xn are negatively associated, if for every I  [n] and every non-decreasing f : RI  R, g : RI  R,
E[f (Xi, i  I)g(Xj, j  I)]  E[f (Xi, i  I)]E[g(Xj, j  I)].

Claim values

i2n.2[0(,[51]],aTnhdeor=emE1[4).ni=L1eXt Xi]1. ,T.h.e.n, ,Xfonrbaennyegati[v0e,ly1]awsseohcaiavteedthraatn: dom

variables

that

take

n
Pr[ Xi > (1 + )]  e-2/3,
i=1

3

n
Pr[ Xi < (1 - )]  e-2/2.
i=1
We apply this to random variables that are formed by selecting a random subset of a fixed size. In particular, we use the following.
Claim 2.3. Let x1, . . . , xn  0 be fixed. For 1  k  n, let R be a uniformly random subset of k elements out of [n]. Let Xi = xi if i  R and Xi = 0 otherwise. Then X1, . . . , Xn are negatively associated.

Proof. For x1 = x2 = . . . = xn = 1, the statement holds by Corollary 11 of [5] (which refers to this distribution as the Fermi-Dirac model). The generalization to arbitrary xi  0 follows from Proposition 4 of [5] with Ij = {j} and hj(t) = xjt.

3 Optimization over the unit cube
We start with optimization over [0, 1]n, arguably the simplest possible polytope. We show that already in this setting, the presence of adversarial noise prevents us from achieving much more than trivial results.

3.1 Convex minimization

First let us consider convex minimization over [0, 1]n. In this setting, we show that errors as small as n-(1-)/2 prevent us from optimizing within a constant additive error.
Theorem 3.1. Let  > 0 be a constant. There are instances of a convex function f : [0, 1]n  [0, 1] accessible through an absolute n-(1-)/2-erroneous oracle, such that a (possibly randomized) algorithm that makes eO(n) queries cannot find a solution of value better than within additive 1/2 - o(1) of the optimum with probability more than e-(n).

We

remark

that

the

proof

of

this

theorem

is

inspired

by

the

proof

of

hardness

of

(

1 2

+

)-

approximation for unconstrained submodular maximization [7]; in particular it can be viewed as

a simple application of the "symmetry gap" argument (see [16] for a more general exposition).

Proof. Let

= n-(1-)/2; we can assume that

<

1 2

,

otherwise

n

is

constant

and

the

statement

is trivial. We will construct an -erroneous oracle (both in the relative and absolute sense) for a

convex function f : [0, 1]n  [0, 1]. Consider a partition of [n] into two subsets A, B of size

|A| = |B| = n/2 (which will be eventually chosen randomly). We define the following function:

*

f (x) =

1 2

+

1 n

(

iA xi -

jB xj ).

This is a convex (in fact linear) function. Next, we define the following modification of f , which could be the function returned by an -erroneous oracle.

* If | * If |

iA xi - iA xi -

jB xj | >

1 2

n, then f(x) = f (x) =

1 2

+

1 n

(

iA xi -

jB xj | 

1 2

n, then f(x) =

1 2

.

jB xj ).

Note that f (x) and f(x) differ only in the region where |

iA xi -

jB xj | 

1 2

n. In particular,

the

value

of

f (x)

in

this

region

is

within

[

1- 2

,

1+ 2

],

while

f(x)

=

1 2

,

so

an

-erroneous oracle for

f (x) (both in the relative and absolute sense) could very well return f(x) instead.

Now assume that (A, B) is a random partition, unknown to the algorithm. We argue that with

high probability, a fixed query x issued by the algorithm will have the property that | iA xi -

jB xj |



1 2

n.

More precisely, since (A, B) is chosen at random subject to |A|

= |B|

=

n/2,

4

we have that iA xi is a sum of negatively associated random variables in [0, 1] (by Claim 2.3).

The expectation of this quantity is  = E[

iA xi]

=

1 2

n i=1

xi



1 2

n.

By

Claim

2.2,

we

have

Pr[

1 xi >  + 4 n] = Pr[

n xi > (1 + 4

)] < e-(n /(4))2/3  e- 2n/24.

iA

iA

Since

1 2

iA

xi

+

1 2

iB

xi

=

1 2

n i=1

xi

=

,

we

get

Pr[ xi -

1 xi > 2 n] = Pr[

xi -  >

1 4

n] < e- 2n/24.

iA

iB

iA

By symmetry,

Pr[|

xi -

xj |

>

1 2

n] < 2e- 2n/24.

iB

jA

We emphasize that this holds for a fixed query x.

Recall that we assumed the algorithm to be deterministic. Hence, as long as its queries satisfy the

property above, the answers will be f(x) = 1/2, and the algorithm will follow the same path of

computation, no matter what the choice of (A, B) is. (Effectively we will not learn anything about

A and B.) Considering the sequence of queries on this computation path, if the number of queries is

t then with probability at least 1-2te- 2n/24 the queries will indeed fall in the region where f(x) =

1/2 and the algorithm will follow this path. If t  e 2n/48, this happens with probability at least

1 - 2e- 2n/48. In this case, all the points queried by the algorithm as well as the returned solution

xout

(by

the same argument)

satisfies

f(xout)

=

1/2,

and hence

f (xout)



1- 2

.

In contrast,

the

actual optimum is f (1B) = 0. Recall that

=

n-(1-)/2;

hence, f (xout)



1 2

(1

-

n-(1-)/2)

and the bounds on the number of queries and probability of success are as in the statement of the

theorem.

Finally, consider a randomized algorithm. Denote by (R1, R2, . . . , ...) the random variables used by the algorithm in its decisions. We can condition on a fixed choice of (R1 = r1, R2 = r2, . . .) which makes the algorithm deterministic. By our proof, the algorithm conditioned on this choice cannot succeed with probability more than e-(n). Since this is true for each particular choice of
(r1, r2, . . .), by averaging it is also true for a random choice of (R1, R2, . . .). Hence, we obtain the same result for randomized algorithms as well.

3.2 Concave maximization

Here we consider the problem of maximizing a concave function f : [0, 1]n  [0, 1]. One can

obtain a result for concave maximization analogous to Theorem 3.1, which we do not state; in

terms of additive errors, there is really no difference between convex minimization and concave

maximization. However, in the case of concave maximization we can also formulate the following

hardness result for multiplicative approximation.

Theorem 3.2. If a concave function f : [0, 1]n  [0, 1] is accessible through a relative--erroneous

oracle, then for any  [0, ], an algorithm that makes less than e 2n/48 queries cannot find a

solution of value greater than

1+ 2

OP T

with probability more than 2e-

2n/48.

Proof. This result follows from the same construction as Theorem 3.1. Recall that f (x) is a linear function, hence also concave. As we mentioned in the proof of Theorem 3.1, f(x) could be the
values returned by a relative -erroneous oracle. Now we consider an arbitrary > 0; note that for   it still holds that f(x) is a relative -erroneous oracle.

By the same proof, an algorithm querying less than e nn/48 points cannot find a solution of value

better

than

1+ 2

with probability more than 2e- 2n/48. In contrast, the optimum of the maximization

problem is supx[0,1]n f (x) = 1. Therefore, the algorithm cannot achieve multiplicative approxi-

mation better than

1+ 2

.

We note that this hardness result is optimal due to the following easy observation.

5

Theorem 3.3. For any concave function f : [0, 1]n  R+, let OP T = supx[0,1]n f (x). Then

f

11 1 , ,...,



1 OP T.

22 2 2

Proof. By compactness, the optimum is attained at a point: let OP T = f (x). Let also x = (1, 1, . . . , 1) - x. We have x  [0, 1]n and hence f (x )  0. By concavity, we obtain

11 1

x + x

f , ,..., = f



f (x) +

f (x

)



1 f (x)

=

1 OP T.

22 2

2

2 22

In

other

words,

a

multiplicative

1 2

-approximation

for

this

problem

is

trivial

to

obtain

--

even

without

asking

any

queries

about

f.

We

just

return

the

point

(

1 2

,

1 2

,

.

.

.

,

1 2

).

Thus

we

can

conclude

that

for

concave maximization, a relative -erroneous oracle is not useful at all.

4 Optimization over polytopes
In this section we consider optimization of convex and concave functions over a polytope P = {x  0 : Ax = b}. We will show inappoximability results for the relative error model. Note that for the absolute error case, the lower bound on convex minimization from the previous section holds, and can be applied to show a lower bound for concave maximization with absolute errors.
Theorem 4.1. Let ,   (0, 1/2) be some constants. There are convex functions for which no algorithm can obtain a finite approximation ratio to minxP f (x) using (en ) queries to a relative -erroneous oracle of the function.
Proof. We will prove our theorem for the case in which P = {x  0 : i xi  n1/2+}. Let H be a subset of indices chosen uniformly at random from all subsets of size exactly n1/2+. We construct two functions:
f (x) = n1+ - n1/2 xi
iH
g(x) = n1+ - n xi
i
Observe that both these functions are convex and non-negative. Also, observe that the minimizer of f is x = 1H and f (x) = 0, while the minimizer of g is any vector x : i xi = n1/2+ and g(x ) = n1+ - n1/2+2 = (n1+). Therefore, the ratio between these two functions is unbounded. We will now construct the erroneous oracle in the following manner:
f (x) = g(x), if (1 - )f (x)  g(x)  (1 + )f (x) f (x) otherwise
By definition, f is an -erroneous oracle to f . The claim will follow from the fact that given access to f one cannot distinguish between f and g using a subexponential number of queries. This implies the inapproximability result since an approximation algorithm which guarantees a finite approximation ratio using a subexponential number of queries could be used to distinguish between the two functions: if the algorithm returns an answer strictly greater than 0 then we know the underlying function is g and otherwise it is f.
Given a query x  [0, 1]n to the oracle, we will consider two cases.
* In case the query x is such that i xi  n1/2 then we have that: n1+ - n  f (x)  n1+
n1+ - n+1/2  g(x)  n1+

6

Since for any ,  > 0 there is a large enough n s.t. n > (1 + )/ , this implies that for any query for which i xi  n1/2 then we have that g(x)  [(1 - )f (x), (1 + )f (x)] and thus the oracle returns g(x).

* In case the query is such that i xi > n1/2 then we can interpret the value of iH xi which determines value of f as a sum of negatively associated random variables
X1, . . . , Xn where Xi realizes with probability n-1/2+ and takes value xi if realized
(see Claim 2.3). We can then apply the Chernoff bound (Claim 2.2), using the fact that E[f (x)] = n1/2- i xi, and get that for any constant 0 <  < 1 we have that with probability 1 - e-(n):

1-

i xi n1/2-



xi 

1+

i xi n1/2-

iH

By using   /(1 + ), this implies that with probability at least 1 - e-(n) we get that:

(1 - )f (x)  g(x)  (1 + )f (x)

Since the likelihood of distinguishing between f and g on a single query is exponentially small in n, the same arguments used throughout the paper imply that it takes an exponen-
tial number of queries to distinguish between f and g.

To conclude, for any query x  [0, 1]n it takes (en ) queries to distinguish between f and g. As discussed above, due to the fact that the ratio between the optima of these two functions is unbounded, this concludes the proof.
Theorem 4.2.  constants ,   (0, 1/2) there is a concave function f : [0, 1]n  R+ for which no algorithm can obtain an approximation strictly better than O(n-1/2+) to maxxP f (x) using (en ) queries to a relative -erroneous oracle of the function.

Proof. We follow a similar methodology as in the proof of Theorem 4.1. We again we select a set H of size n1/2+ u.a.r. and construct two functions: f (x) = n1/2 iH xi + n1/2+ and g(x) = n i xi + .n1/2+ As in the proof of Theorem 4.1 the noisy oracle f (x) = g(x) when
(1 - )f (x)  g(x)  (1 + )f (x) and otherwise f (x) = f (x). Note that both functions are concave and non-negative, and by its definition the oracle is -erroneous for the function f . For b = n1/2+ it is easy to see that the optimal value when the objective is f is n1+ while the optimal value is O(n1/2+) when the objective is g, which implies that one cannot obtain an approximation better than (n-1/2+) with a subexponential number of queries. In case the query to the oracle is a point x s.t. i xi  n1/2, then by Chernoff bound arguments, similar to the ones we used above, with probability at least 1 - e-(n) we get (1 - )f (x)  g(x)  (1 + )f (x). Thus, for any query in which i xi  n1/2, the likelihood of the oracle returning f is exponentially small in n.
In case the query is a point x s.t. i xi > n1/2 standard concentration bound arguments as before, imply that with probability at least 1 - e-(n) we get (1 - )f (x)  g(x)  (1 + )f (x). Since the likelihood of distinguishing between f and g on a single query is exponentially small in n, we can conclude that it takes an exponential number of queries to distinguish between f and g.

5 Optimization over assignments

In this section, we consider the concave maximization problem over a more specific polytope,



k

Pn,k

=

 x



Rn+xk

:

 xij = 1 i  [n] .

 j=1



This can be viewed as the matroid polytope for a partition matroid on n blocks of k elements, or

alternatively the convex hull of assignments of n items to k agents. In this case, there is a trivial

1 k

-approximation,

similar

to

the

1 2

-approximation

in

the

case

of

a

unit

cube.

7

Theorem 5.1. For any k  2 and a concave function f : Pn,k  R+, let OP T = supxPn,k f (x).

Then

f

11 1 , ,...,



1 OP T.

kk k k

Proof. By compactness, the optimum is attained at a point: let OP T = f (x). Let x(ij) =

xi,(j+ mod k) ; i.e., x( ) is a cyclic shift of the coordinates of x by in each block. We have

x(

)



Pn,k

and

1 k

k-1 =0

x(ij)

=

1 k

k j=1

xij

=

1 k

.

By

concavity

and

nonnegativity

of

f,

we

obtain

f

11 1 , ,...,

=f

1 k-1 x( )



1 f (x(0))

=

1 OP T.

kk k

k

kk

=0

We show that this approximation is best possible, if we have access only to a -erroneous oracle.

Theorem 5.2. If k  2 and a concave function f : Pn,k  [0, 1] is accessible through a relative--

erroneous oracle, then for any  [0, ], an algorithm that makes less than e 2n/6k queries cannot

find a solution of value greater than

1+ k

OP T

with probability more than 2e-

2 n/6k .

Note that this result is nontrivial only for n k. In other words, the hardness factor of k is never

worse than a square root of the dimension of the problem. Therefore, this result can be viewed as

interpolating between the hardness of

1+ 2

-approximation over the unit cube (Theorem 3.2), and the

hardness of n-1/2-approximation over a general polytope (Theorem 4.2).

Proof. Given  : [n]  [k], we construct a function f  : Pn,k  [0, 1] (where  describes the intended optimal solution):

*

f (x) =

1 n

n i=1

xi,(i).

Next we define a modified function f as follows:

*

If |f (x) -

1 k

|

>

k

then f(x) = f (x)

*

If |f (x) -

1 k

|



k

then f(x) =

1 k

.

By definition, f (x) and f(x) differ only if |f (x) -

1 k

|



k , and then f (x)



[

1- k

,

1+ k

] while

f (x)

=

1 k

.

Therefore,

f (x)

is

a

valid

relative

-erroneous oracle for f .

Similarly to the proofs above, we argue that if  is chosen uniformly at random, then with high

probability

f (x)

=

1 k

for

any

fixed

query

x



Pn,k .

This

holds

again

by

a

Chernoff

bound:

For

a

fixed xij such that

k j=1

xij

=

1,

we

have

that

f (x)

=

1 n

n i=1

xi,(i)

=

1 n

Z

where

Z

is

a

sum

of

independent

random

variables

with

expectation

1 k

i,j

xij

=

n k

.

The

random

variables

attain

values

in

[0,

1].

By

the

Chernoff

bound,

Pr[|Z

-

n k

|

>

n k

]

<

2e-

2 n/3k .

This

gives

Pr |f (x) - 1 | > < 2e- 2n/3k. kk

By the same arguments as before, if the algorithm asks less than e 2n/6k queries, then it will not

detect

a

point

such

that

|f (x) -

1 k

|

>

k

with

probability

more

than

2e-

2 n/6k .

Then

the

query

an-

swers will all be f(x) the optimum solution is

=xi,k1(ai)nd=th1efovralaulel

of the returned solution i, which gives f (x) =

will 1.

be

at

most

1+ k

.

Meanwhile,

Acknowledgements. YS was supported by NSF grant CCF-1301976, CAREER CCF-1452961 and a Google Faculty Research Award.

8

References
[1] Alekh Agarwal, Ofer Dekel, and Lin Xiao. Optimal algorithms for online convex optimization with multi-point bandit feedback. In COLT 2010 - The 23rd Conference on Learning Theory, Haifa, Israel, June 27-29, 2010, pages 28-40, 2010.
[2] Alekh Agarwal, Dean P. Foster, Daniel Hsu, Sham M. Kakade, and Alexander Rakhlin. Stochastic convex optimization with bandit feedback. SIAM Journal on Optimization, 23(1):213-240, 2013.
[3] Alexandre Belloni, Tengyuan Liang, Hariharan Narayanan, and Alexander Rakhlin. Escaping the local minima via simulated annealing: Optimization of approximately convex functions. COLT 2015.
[4] Sebastien Bubeck and Nicolo Cesa-Bianchi. Regret analysis of stochastic and nonstochastic multi-armed bandit problems. Foundations and Trends in Machine Learning, 5(1):1-122, 2012.
[5] Devdatt Dubhashi, Volker Priebe, and Desh Ranjan. Negative dependence through the FKG inequality. In Research report MPI-I-96-1-020, Max-Planck Institut fur Informatik, Saarbrucken, 1996.
[6] John C. Duchi, Michael I. Jordan, Martin J. Wainwright, and Andre Wibisono. Optimal rates for zeroorder convex optimization: The power of two function evaluations. IEEE Transactions on Information Theory, 61(5):2788-2806, 2015.
[7] Uriel Feige, Vahab S. Mirrokni, and Jan Vondrak. Maximizing non-monotone submodular functions. SIAM J. Comput., 40(4):1133-1153, 2011.
[8] Abraham Flaxman, Adam Tauman Kalai, and H. Brendan McMahan. Online convex optimization in the bandit setting: gradient descent without a gradient. In Proceedings of the Sixteenth Annual ACM-SIAM Symposium on Discrete Algorithms, SODA 2005, Vancouver, British Columbia, Canada, January 23-25, 2005, pages 385-394, 2005.
[9] Kevin G. Jamieson, Robert D. Nowak, and Benjamin Recht. Query complexity of derivative-free optimization. In Advances in Neural Information Processing Systems 25: 26th Annual Conference on Neural Information Processing Systems 2012. Proceedings of a meeting held December 3-6, 2012, Lake Tahoe, Nevada, United States., pages 2681-2689, 2012.
[10] A.S. Nemirovsky and D.B. Yudin. Problem Complexity and Method Efficiency in Optimization. J. Wiley & Sons, New York, 1983.
[11] Yurii Nesterov. Random gradient-free minimization of convex functions. CORE Discussion Papers 2011001, Universite catholique de Louvain, Center for Operations Research and Econometrics (CORE), 2011.
[12] Aaditya Ramdas, Barnabas Poczos, Aarti Singh, and Larry A. Wasserman. An analysis of active learning with uniform feature noise. In Proceedings of the Seventeenth International Conference on Artificial Intelligence and Statistics, AISTATS 2014, Reykjavik, Iceland, April 22-25, 2014, pages 805-813, 2014.
[13] Aaditya Ramdas and Aarti Singh. Optimal rates for stochastic convex optimization under tsybakov noise condition. In Proceedings of the 30th International Conference on Machine Learning, ICML 2013, Atlanta, GA, USA, 16-21 June 2013, pages 365-373, 2013.
[14] Ohad Shamir. On the complexity of bandit and derivative-free stochastic convex optimization. In COLT 2013 - The 26th Annual Conference on Learning Theory, June 12-14, 2013, Princeton University, NJ, USA, pages 3-24, 2013.
[15] Sebastian U. Stich, Christian L. Muller, and Bernd Gartner. Optimization of convex functions with random pursuit. CoRR, abs/1111.0194, 2011.
[16] Jan Vondrak. Symmetry and approximability of submodular maximization problems. SIAM J. Comput., 42(1):265-304, 2013.
9

