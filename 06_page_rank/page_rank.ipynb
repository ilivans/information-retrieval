{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from time import sleep\n",
    "from heapq import heappop, heappushpop\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "from link_parser import LinkParser\n",
    "\n",
    "logging.basicConfig(filename=\"/media/ssd/simple.wiki/spider.log\",\n",
    "                    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "                    datefmt='%I:%M:%S %p',\n",
    "                    filemode='w',\n",
    "                    level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На этапе фильтрации при помощи регулярного выражения отбираются url-ы, ведущие на уникальные вики-страницы. Эти страницы имеют доменное имя simple.wikipedia.org и лежат по пути wiki. По интересующему пути simple.wikipedia.org/wiki/ также лежат служебные страницы, начинающиеся на File:, Help:, Special: и т.д., которые отбрасываются во время фильтрации (при этом нельзя отбрасывать любой url с символом ':', т.к. существуют такие страницы, как \"ISO_3166-2:BR\" или \"Star_Trek:_Phase_II\"). Ещё одним особым случаем является url по вышеуказанному пути, чья уникальная часть начинается на символ '#' (например, simple.wikipedia.org/wiki/#blabla) - такой url редиректит на главную страницу. Его также считаем невалидным (*встретился после посещения половины всех страниц при самом первом заходе).\n",
    "\n",
    "На этапе нормализации из url-а отбрасывается часть, начинающаяся с хештега, т.к. она содержит в себе лишь информацию об определённом положении на странице. Также отсекается внутренний путь страницы, идущий за слешем после названия страницы.\n",
    "\n",
    "При обходе поддерживаются множества url-ов to_visit и visited (в первом не могут содержаться объекты из второго). Также во время обхода строится ориентированный граф из страниц для дальнейшего вычисления PageRank-а."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL u'https://simple.wikipedia.org/wiki/Seljuk_Sultanate_of_R\\xfbm' contains non-ASCII characters\n",
      "[Errno socket error] [Errno 104] Connection reset by peer\n",
      "[Errno socket error] [Errno -3] Temporary failure in name resolution\n",
      "[Errno socket error] [Errno -3] Temporary failure in name resolution\n",
      "[Errno socket error] [Errno -3] Temporary failure in name resolution\n",
      "[Errno socket error] [Errno -3] Temporary failure in name resolution\n",
      "URL u'https://simple.wikipedia.org/wiki/Berg\\xfcn' contains non-ASCII characters\n",
      "URL u'https://simple.wikipedia.org/wiki/Kingdom_of_France_(1791\\u20131792)' contains non-ASCII characters\n",
      "URL u'https://simple.wikipedia.org/wiki/History_of_Sweden_(800\\u20131521)' contains non-ASCII characters\n",
      "URL u'https://simple.wikipedia.org/wiki/Guimar\\xe3es' contains non-ASCII characters\n",
      "URL u'https://simple.wikipedia.org/wiki/Republic_of_Lithuania_(1918\\u20131940)' contains non-ASCII characters\n",
      "URL u'https://simple.wikipedia.org/wiki/History_of_Sweden_(1772\\u20131809)' contains non-ASCII characters\n",
      "URL u'https://simple.wikipedia.org/wiki/B\\xfcndnis_90' contains non-ASCII characters\n",
      "URL u'https://simple.wikipedia.org/wiki/Lithuanian_Soviet_Socialist_Republic_(1918\\u20131919)' contains non-ASCII characters\n",
      "URL u'https://simple.wikipedia.org/wiki/Republic_of_the_Congo_(L\\xe9opoldville)' contains non-ASCII characters\n",
      "[Errno socket error] [Errno 101] Network is unreachable\n",
      "URL u'https://simple.wikipedia.org/wiki/History_of_the_Philippines_(1946\\u20131965)' contains non-ASCII characters\n",
      "URL u'https://simple.wikipedia.org/wiki/Duchy_of_Limburg_(1839\\u20131867)' contains non-ASCII characters\n",
      "URL u'https://simple.wikipedia.org/wiki/General_classification_in_the_Vuelta_a_Espa\\xf1a' contains non-ASCII characters\n",
      "URL u'https://simple.wikipedia.org/wiki/Denmark\\u2013Norway' contains non-ASCII characters\n",
      "URL u'https://simple.wikipedia.org/wiki/Electorate_of_W\\xfcrttemberg' contains non-ASCII characters\n",
      "URL u'https://simple.wikipedia.org/wiki/Emirate_of_C\\xf3rdoba' contains non-ASCII characters\n",
      "URL u'https://simple.wikipedia.org/wiki/Free_People%27s_State_of_W\\xfcrttemberg' contains non-ASCII characters\n",
      "URL u'https://simple.wikipedia.org/wiki/Free_Peoples%27_State_of_W\\xfcrttemberg' contains non-ASCII characters\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "link_parser = LinkParser()\n",
    "to_visit = {\"https://simple.wikipedia.org/wiki/Main_Page\"}  # starting url\n",
    "visited = set()\n",
    "graph = nx.DiGraph()\n",
    "bad_urls = []\n",
    "\n",
    "def spider(delay=0.1):\n",
    "    global link_parser, to_visit, visited, graph\n",
    "    while len(to_visit):\n",
    "        url = to_visit.pop()\n",
    "        logging.info(\"%s: %s\", len(visited), url)\n",
    "        graph.add_node(url)\n",
    "        visited.add(url)\n",
    "        try:\n",
    "            links = link_parser.get_links(url)\n",
    "        except Exception as e:\n",
    "            print e\n",
    "            logging.error(e)\n",
    "            bad_urls.append(url)\n",
    "            continue        \n",
    "        to_visit = to_visit.union(links - visited)\n",
    "        graph.add_edges_from(zip([url] * len(links), links))\n",
    "        sleep(delay)\n",
    "\n",
    "spider(0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно, у небольшого числа урлов оказалась проблема с кодировкой, дропнем их из графа. И посмотрим сколько страниц нашли."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph.remove_nodes_from(bad_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135318"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.number_of_nodes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "135318 из 123771 уникальных страниц. Предполагаю, что причина превосходства числа найденных страниц связанно с наличием редиректов, которые не предлагалось обрабатывать."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем PageRank и найдём 20 топовых страниц."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 38s, sys: 924 ms, total: 1min 39s\n",
      "Wall time: 1min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pagerank = nx.pagerank(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top20 = [0.] * 20\n",
    "for url, rank in pagerank.iteritems():\n",
    "    heappushpop(top20, (rank, url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0011737667132 https://simple.wikipedia.org/wiki/Germany\n",
      "0.001187208145 https://simple.wikipedia.org/wiki/Association_football\n",
      "0.00119092877372 https://simple.wikipedia.org/wiki/Movie\n",
      "0.00119112473273 https://simple.wikipedia.org/wiki/Government\n",
      "0.00120016830024 https://simple.wikipedia.org/wiki/Europe\n",
      "0.00120024361172 https://simple.wikipedia.org/wiki/Television\n",
      "0.00124078709979 https://simple.wikipedia.org/wiki/City\n",
      "0.00133306869528 https://simple.wikipedia.org/wiki/England\n",
      "0.00138645648289 https://simple.wikipedia.org/wiki/Wikimedia_Commons\n",
      "0.00142378722101 https://simple.wikipedia.org/wiki/Country\n",
      "0.00150814436333 https://simple.wikipedia.org/wiki/International_Standard_Book_Number\n",
      "0.00154114677339 https://simple.wikipedia.org/wiki/Geographic_coordinate_system\n",
      "0.00158951577699 https://simple.wikipedia.org/wiki/United_Kingdom\n",
      "0.00161383908321 https://simple.wikipedia.org/wiki/English_language\n",
      "0.00171625717977 https://simple.wikipedia.org/wiki/Japan\n",
      "0.00194699256684 https://simple.wikipedia.org/wiki/Definition\n",
      "0.0022335082908 https://simple.wikipedia.org/wiki/France\n",
      "0.00421364219491 https://simple.wikipedia.org/wiki/United_States\n",
      "0.00523352769261 https://simple.wikipedia.org/wiki/Multimedia\n",
      "0.0403967868691 https://simple.wikipedia.org/wiki/Main_Page\n"
     ]
    }
   ],
   "source": [
    "while top20:\n",
    "    rank, url = heappop(top20)\n",
    "    print rank, url"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
