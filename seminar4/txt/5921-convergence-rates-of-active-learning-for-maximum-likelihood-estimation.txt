Convergence Rates of Active Learning for Maximum Likelihood Estimation
Kamalika Chaudhuri  Sham M. Kakade  Praneeth Netrapalli  Sujay Sanghavi 
Abstract
An active learner is given a class of models, a large set of unlabeled examples, and the ability to interactively query labels of a subset of these examples; the goal of the learner is to learn a model in the class that fits the data well. Previous theoretical work has rigorously characterized label complexity of active learning, but most of this work has focused on the PAC or the agnostic PAC model. In this paper, we shift our attention to a more general setting - maximum likelihood estimation. Provided certain conditions hold on the model class, we provide a two-stage active learning algorithm for this problem. The conditions we require are fairly general, and cover the widely popular class of Generalized Linear Models, which in turn, include models for binary and multi-class classification, regression, and conditional random fields. We provide an upper bound on the label requirement of our algorithm, and a lower bound that matches it up to lower order terms. Our analysis shows that unlike binary classification in the realizable case, just a single extra round of interaction is sufficient to achieve near-optimal performance in maximum likelihood estimation. On the empirical side, the recent work in [12] and [13] (on active linear and logistic regression) shows the promise of this approach.
1 Introduction
In active learning, we are given a sample space X , a label space Y, a class of models that map X to Y, and a large set U of unlabelled samples. The goal of the learner is to learn a model in the class with small target error while interactively querying the labels of as few of the unlabelled samples as possible. Most theoretical work on active learning has focussed on the PAC or the agnostic PAC model, where the goal is to learn binary classifiers that belong to a particular hypothesis class [2, 14, 10, 7, 3, 4, 22], and there has been only a handful of exceptions [19, 9, 20]. In this paper, we shift our attention to a more general setting - maximum likelihood estimation (MLE), where Pr(Y |X) is described by a model  belonging to a model class . We show that when data is generated by a model in this class, we can do active learning provided the model class  has the following simple property: the Fisher information matrix for any model  2  at any (x, y) depends only on x and . This condition is satisfied in a number of widely applicable model classes, such as Linear Regression and Generalized Linear Models (GLMs), which in turn includes models for Multiclass Classification and Conditional Random Fields. Consequently, we can provide active learning algorithms for maximum likelihood estimation in all these model classes. The standard solution to active MLE estimation in the statistics literature is to select samples for label query by optimizing a class of summary statistics of the asymptotic covariance matrix of the
Dept. of CS, University of California at San Diego. Email: kamalika@cs.ucsd.edu Dept. of CS and of Statistics, University of Washington. Email: sham@cs.washington.edu Microsoft Research New England. Email:praneeth@microsoft.com Dept. of ECE, The University of Texas at Austin. Email:sanghavi@mail.utexas.edu
1

estimator [6]. The literature, however, does not provide any guidance towards which summary statistic should be used, or any analysis of the solution quality when a finite number of labels or samples are available. There has also been some recent work in the machine learning community [12, 13, 19] on this problem; but these works focus on simple special cases (such as linear regression [19, 12] or logistic regression [13]), and only [19] involves a consistency and finite sample analysis. In this work, we consider the problem in its full generality, with the goal of minimizing the expected log-likelihood error over the unlabelled data. We provide a two-stage active learning algorithm for this problem. In the first stage, our algorithm queries the labels of a small number of random samples from the data distribution in order to construct a crude estimate 1 of the optimal parameter . In the second stage, we select a set of samples for label query by optimizing a summary statistic of the covariance matrix of the estimator at 1; however, unlike the experimental design work, our choice of statistic is directly motivated by our goal of minimizing the expected log-likelihood error, which guides us towards the right objective. We provide a finite sample analysis of our algorithm when some regularity conditions hold and when the negative log likelihood function is convex. Our analysis is still fairly general, and applies to Generalized Linear Models, for example. We match our upper bound with a corresponding lower bound, which shows that the convergence rate of our algorithm is optimal (except for lower order terms); the finite sample convergence rate of any algorithm that uses (perhaps multiple rounds of) sample selection and maximum likelihood estimation is either the same or higher than that of our algorithm. This implies that unlike what is observed in learning binary classifiers, a single round of interaction is sufficient to achieve near-optimal log likelihood error for ML estimation.
1.1 Related Work
Previous theoretical work on active learning has focussed on learning a classifier belonging to a hypothesis class H in the PAC model. Both the realizable and non-realizable cases have been considered. In the realizable case, a line of work [7, 18] has looked at a generalization of binary search; while their algorithms enjoy low label complexity, this style of algorithms is inconsistent in the presence of noise. The two main styles of algorithms for the non-realizable case are disagreementbased active learning [2, 10, 4], and margin or confidence-based active learning [3, 22]. While active learning in the realizable case has been shown to achieve an exponential improvement in label complexity over passive learning [2, 7, 14], in the agnostic case, the gains are more modest (sometimes a constant factor) [14, 10, 8]. Moreover, lower bounds [15] show that the label requirement of any agnostic active learning algorithm is always at least (2/2), where  is the error of the best hypothesis in the class, and  is the target error. In contrast, our setting is much more general than binary classification, and includes regression, multi-class classification and certain kinds of conditional random fields that are not covered by previous work. [19] provides an active learning algorithm for linear regression problem under model mismatch. Their algorithm attempts to learn the location of the mismatch by fitting increasingly refined partitions of the domain, and then uses this information to reweight the examples. If the partition is highly refined, then the computational complexity of the resulting algorithm may be exponential in the dimension of the data domain. In contrast, our algorithm applies to a more general setting, and while we do not address model mismatch, our algorithm has polynomial time complexity. [1] provides an active learning algorithm for Generalized Linear Models in an online selective sampling setting; however, unlike ours, their input is a stream of unlabelled examples, and at each step, they need to decide whether the label of the current example should be queried. Our work is also related to the classical statistical work on optimal experiment design, which mostly considers maximum likelihood estimation [6]. For uni-variate estimation, they suggest selecting samples to maximize the Fisher information which corresponds to minimizing the variance of the regression coefficient. When  is multi-variate, the Fisher information is a matrix; in this case, there are multiple notions of optimal design which correspond to maximizing different parameters of the Fisher information matrix. For example, D-optimality maximizes the determinant, and A-optimality maximizes the trace of the Fisher information. In contrast with this work, we directly optimize the expected log-likelihood over the unlabelled data which guides us to the appropriate objective function; moreover, we provide consistency and finite sample guarantees.
2

Finally, on the empirical side, [13] and [12] derive algorithms similar to ours for logistic and linear regression based on projected gradient descent. Notably, these works provide promising empirical evidence for this approach to active learning; however, no consistency guarantees or convergence rates are provided (the rates presented in these works are not stated in terms of the sample size). In contrast, our algorithm applies more generally, and we provide consistency guarantees and convergence rates. Moreover, unlike [13], our logistic regression algorithm uses a single extra round of interaction, and our results illustrate that a single round is sufficient to achieve a convergence rate that is optimal except for lower order terms.

2 The Model

We begin with some notation. We are given a pool U = {x1, . . . , xn} of n unlabelled examples drawn from some instance space X , and the ability to interactively query labels belonging to a label space Y of m of these examples. In addition, we are given a family of models M = {p(y|x, ),  2 } parameterized by  2   Rd. We assume that there exists an unknown parameter  2  such that querying the label of an xi 2 U generates a yi drawn from the distribution p(y|xi, ). We also abuse notation and use U to denote the uniform distribution over the examples in U .

We consider the fixed-design (or transductive) setting, where our goal is to minimize the error on the fixed set of points U . For any x 2 X , y 2 Y and  2 , we define the negative log-likelihood function L(y|x, ) as:
L(y|x, ) = log p(y|x, )

Our goal is to find a  to minimize LU (), where

LU () = EXU,Y p(Y |X,)[L(Y |X, )]

by interactively querying labels for a subset of U of size m, where we allow label queries with replacement i.e., the label of an example may be queried multiple times.

An additional quantity of interest to us is the Fisher information matrix, or the Hessian of the negative log-likelihood L(y|x, ) function, which determines the convergence rate. For our active learning procedure to work correctly, we require the following condition.

Condition 1. For any x 2 X , y 2 Y, x and  (and does not depend on y.)



2

,

the

Fisher

information

@ 2 L(y |x,) @2

is

a

function

of

only

Condition 1 is satisfied by a number of models of practical interest; examples include linear regression and generalized linear models. Section 5.1 provides a brief derivation of Condition 1 for generalized linear models.

For this

any x, is just

y and , we use I(x, ) to a function of x and . Let

debneoatneythdeisHtriebsusitaionn@o2vLe@(ry2|txh,e)u;nolabbseerllveedtshaamt bpyleAs isnsuUm;pftoior nan1y,

 2 , we use:

I () = EX [I(X, )]

3 Algorithm

The main idea behind our algorithm is to sample xi from a well-designed distribution over U , query the labels of these samples and perform ML estimation over them. To ensure good performance, should be chosen carefully, and our choice of is motivated by Lemma 1. Suppose the labels yi are generated according to: yi  p(y|xi, ). Lemma 1 states that the expected loglikelihood error of the ML estimate with respect to m samples from in this case is essentially Tr I () 1IU () /m.

This suggests selecting as the distribution  that minimizes Tr I  () 1IU () . Unfortu-

nately, we cannot do this as  is unknown. We resolve this problem through a two stage algorithm;

in the first stage, we use a small number m1 of samples to construct a coarse estimate 1 of  (Steps

1-2). draw

In the second samples from

s(taagslei,gwhtemcoaldciufilcaatetioandiosft)ritbhuistidoinstri1bwuthioicnhfomrianifimniezreessTtirmaIti1o(no1)f

1IU (1)  (Steps

and 3-5).

3

Algorithm 1 ActiveSetSelect

Input: Samples xi, for i = 1, * * * , n

1: Draw m1 samples u.a.r from U , and query their labels to get S1. 2: Use S1 to solve the MLE problem:

X

1 = argmin2

L(yi|xi, )

(xi ,yi )2S1

3: Solve the following SDP (refer Lemma 3): a = argminaTr S 1IU (1)

( s.t.

P S = i aiI(xi, 1)
P0  ai  1 i ai = m2

4: Draw m2 examples using probability =  1 + (1 )U where the distribution

5:

=1 Use S2

tomso2l1v/e6.thQeuMerLyEthperiorblalebmel:s to get S2.

X

2 = argmin2

L(yi|xi, )

(xi ,yi )2S2

Output: 2

1

=

ai m2

and

The distribution 1 is modified slightly to  (in Step 4) to ensure that I() is well conditioned with respect to IU (). The algorithm is formally presented in Algorithm 1. Finally, note that Steps 1-2 are necessary because IU and I are functions of . In certain special cases such as linear regression, IU and I are independent of . In those cases, Steps 1-2 are unnecessary, and we may skip directly to Step 3.

4 Performance Guarantees

The following regularity conditions are essentially a quantified version of the standard Local Asymptotic Normality (LAN) conditions for studying maximum likelihood estimation (see [5, 21]). Assumption 1. (Regularity conditions for LAN)

1. Smoothness: The first three derivatives of L(y|x, ) exist in all interior points of   Rd.

2. Compactness:  is compact and  is an interior point of .

3.

Strong Convexity: value min > 0.

IU ()

=

1 n

Pn
i=1

I

(xi,

)

is

positive

definite

with

smallest

singular

4. Lipschitz continuity: There exists a neighborhood B of  and a constant L3 such that for all x 2 U , I(x, ) is L3-Lipschitz in this neighborhood.

IU () 1/2 (I (x, ) for every , 0 2 B.

I (x, 0)) IU () 1/2  L3 k
2

0kIU () ,

5. Concentration at : For any x 2 U and y, we have (with probability one),

krL(y|x, )kIU () 1  L1, and

IU () 1/2I (x, ) IU () 1/2  L2.
2

6. Boundedness: max(x,y) sup2 |L(x, y|)|  R. In addition to the above, we need one extra condition which is essentially a pointwise self concordance. This condition is satisfied by a vast class of models, including the generalized linear models.

4

Assumption 2. Point-wise self concordance:

L4 k k2 I (x, ) I (x, ) I (x, ) L4 k k2 I (x, ) .

Definition 1. [Optimal Sampling Distribution over the points in U as the distribution  =

]

(

 1

We ,..

define

.,

 n

)

the for

wohpitcimh alisamp0li,nPg diisitrib=uti1o,nand

Tr I  () 1IU () is as small as possible.

Definition 1 is motivated by Lemma 1, which indicates that under some mild regularity conditions, a ML estimate calculated on samples drawn from  will provide the best convergence rates (including the right constant factor) for the expected log-likelihood error.

We now present the main result of our paper. The proof of the following theorem and all the supporting lemmas will be presented in Appendix A.

Theorem 1. Suppose the regularity conditions in Assumptions 1 and 2 hold.

Let 

10, and the number of samples

O

max

L2 log2 d, L21

L23 +

1
min

log2

d,

diameter()
Tr(IU () 1

)

,

used 2L24 Tr

 in IU

step () 1

(1) .

be m1 Then

> with

probability 1 as:
E [LU (2)]

, the expected log likelihood error of the estimate 2 of Algorithm 1 is bounded

 LU ()  1 +

2

4 1 (1

 + em2 )Tr I

 ()

 1IU ()

1 m2

+

R m22

,

(1)

where  O L1L3

+

pis L2theplmogo12/dp6mtim2 al.

sampling distribution in Definition 1 and Moreover, for any sampling distribution

em2 = satisfying

I ()  cIU () and label constraint of m2, we have the following lower bound on the

expected log likelihood error for ML estimate:

hi E LU (b )

LU ()

(1

 m2 ) Tr I

()

1IU

 ()

1 m2

L21 cm22

,

(2)

where m2

d=ef

.em2
c2 m12/3

Remark 1. (Restricting to Maximum Likelihood Estimation) Our restriction to maximum likelihood

estimators is minor, as this is close to minimax optimal (see [16]). Minor improvements with certain

kinds of estimators, such as the James-Stein estimator, are possible.

4.1 Discussions
Several remarks about Theorem 1 are in order. The high probability bound in Theorem 1 is with respect to the samples drawn in S1; provided these samples are representative (which happens with probability 1 ), the output 2 of Algorithm 1 will satisfy (1). Additionally, Theorem 1 assumes that the labels are sampled with replacement; in other words, we can query the label of a point xi multiple times. Removing this assumption is an avenue for future work.
 Second, the highest order term in both (1) and (2) is Tr I  () 1IU () /m. The terms involving iaanmnnvdd2omolav(ni2pnd,gmaenm2d2)i,naast(rh1eleo)lncoigoswnoaevsfrearoglr=oedwnecoree(raprsoarmbtdeoe2tor)hf,amosmuw1r2eiaaslllng.adolOsreoibtmshoe2mfrvaairesleotohwopa(ett1irm)o. araMdllseeoorxrtcmeheoaepvnatesmfruo,rr2ief.lsoTtwhh=eeurstr,o!aprd(dr1eoe)ovr,fitftdehberemdentswt.heiesen!tem(r1m1) Finally, the lower bound (2) applies to distributions for which I () cIU (), where c occurs in the lower order terms of the bound. This constraint is not very restrictive, and does not affect the asymptotic rate. Observe that IU () is full rank. If I () is not full rank, then the expected log likelihood error of the ML estimate with respect to will not be consistent, and thus such a will never achieve the optimal rate. If I () is full rank, then there always exists a c for which I () cIU (). Thus (2) essentially states that for distributions where I () is close to being rank-deficient, the asymptotic convergence rate of O(Tr I () 1IU () /m2) is achieved at larger values of m2.

5

4.2 Proof Outline Our main result relies on the following three steps.

4.2.1 Bounding the Log-likelihood Error

First, we characterize the log likelihood error (wrt U ) of the empirical risk minimizer (ERM) estimate obtained using a sampling distribution . Concretely, let be a distribution on U . Let b be the ERM estimate using the distribution :

b

=

argmin2

1 m2

Xm2
i=1

L(Yi|Xi,

),

(3)

where Xi  and Yi  p(y|Xi, ).hThecoreof our analyisis is Lemma 1, which shows a precise estimate of the log likelihood error E LU b LU () .

Lemma 1. Suppose L satisfies the regularity conditions in Assumptions 1 and 2. Let be a dis-

tribution on U and b be the ERM estimate (3) using m2 labeled examples. Suppose further that

I () m2 d=ef

 cIU

O

1 c2

() for some p
L1L3 + L2

coqnstant c <1.

p log dm2 m2

<

Then, 1, we

for any have:

p

2 and m2 large enough such that

(1

m2

)

2 m2

L21 cmp2/2



h E LU

 b



where

2

d=ef

Tr

 I

()

 1IU () .

LU

i ()



(1

+

m2

)

2 m2

+

R mp2

,

4.2.2 Approximating 

Lem ma 1 motivates sampling from the optimal sampling distribution  that minimizes Tr I  () 1IU () . However, this quantity depends on , which we do not know. To resolve this issue, our algorithm first queries the labels of a small fraction of points (m1) and solves a ML estimation problem to obtain a coarse estimate 1 of .

How close should 1 be to ? Our analysis indicates that it is sufficient for 1 to be close enough that for any x, I(x, 1) is a constant factor spectral approximation to I(x, ); the number of samples needed to achieve this is analyzed in Lemma 2.

Lemma 2. Suppose L satisfies the regularity conditions in Assumptions 1 and 2. If the number of

samples used in the first step

00



m1 > O @max @L2 log2 d, L21 L23 +

1

 log2 d,

diameter() ,

min Tr IU () 1

11

2L24

Tr

 IU

()

 1 AA ,

then, we have:

1 I (x, ) I (x, 1) I (x, ) 1 I (x, ) 8 x 2 X

with probability greater than 1 .

4.2.3 Computing 1

Third, we are left with the task of obtaining a distribution 1 that minimizes the log likelihood error. We now pose this optimization problem as an SDP.

From Lemmas 1 and2, [n]) minimizing Tr I sition (svd) of IU (1).

it is clear (1) 1IU
Since Tr

t(hIa1t)(w.1e)Lshe1toIIuUUld((a1i1m))=to=PobPjtadjin=jv1ajsvajjmv>jp>bliIentg(hde1iss)itnri1gbvuujlta,iorthnviaslui=se ed(qemuacii2ovma:lpieon2-t

6

to solving:

Xd

min
a,c

j cj

j=1

8 >< s.t. >:

P

S

= vj >

S

i

aiI(xi, 1) 1vj  cj

Pai 2 [0, 1]

i ai = m2.

(4)

Among the above constraints, the complement formula tells us that:

concjstravinjt>vj vj S

>S 

1vj  cj seems problematic. However, Schur 0 , S  0 and vj>S 1vj  cj. In our case,

we know that S  0, since it is a sum of positive semi definite matrices. The above argument proves

the following lemma.

Lemma 3. The following two optimization programs are equivalent:

mina,c

mina s.t.

Tr PS 1IU (1) S = i aiI(xi, 1)
Pai 2 [0, 1]



s.t.

i ai = m2.

where

IU

(1)

=

P
j

jvjvj> denotes the svd of IU (1).

Pd Pj=1

j cj

S = i aiI(xi, 1)

cj vj > vj S

0

Pai 2 [0, 1]

i ai = m2,

5 Illustrative Examples

We next present some examples that illustrate Theorem 1. We begin by showing that Condition 1 is satisfied by the popular class of Generalized Linear Models.

5.1 Derivations for Generalized Linear Models

A generalized linear model is specified by three parameters - a linear model, a sufficient statis-

tic, and a member of the exponential family. Let  be a linear model:  = >X. Then, in a

Generalized Linear Model (GLM), Y is drawn from an exponential family distribution with pa-

rameter . Specifically, p(Y = y|) = e>t(y) A(), where t(*) is the sufficient statistic and

A(*) is the log-partition function. From properties of the exponential family, the log-likelihood

is written as log p(y|) = >t(y) A(). If we take  = >x, and take the derivative with

respect to , we have:

@ log p(y|,x) @

= xt(y)

xA0(>x). Taking derivatives again gives us

@2 log p(y|,x) @2

=

xx>A00(>x), which is independent of y.

5.2 Specific Examples

We next present three illustrative examples of problems that our algorithm may be applied to.

Linear Regression. Our first example is linear regression. In this case, x 2 Rd and Y 2 R are

generated N (0, 1).

according to In this case,

the the

ndeisgtaritbivuetiolong:liYkel=ihoo>dXfu+nctio, nwihse:reL(yi|sx,an)oi=se

variable drawn from (y >x)2, and the

corresponding Fisher information matrix I(x, ) is given as: I(x, ) = xx>. Observe that in this

(very special) case, the Fisher information matrix does not depend on ; as a result

the first two steps of the algorithm, and proceed directly to step 3. covariance matrix of U , then Theorem 1 tells us that we need to query

If  labels

=fromn1

wPa ediicsxatirnxibeiu>litmioisinntahtee

with covariance matrix  such that Tr  1 is minimized.

We illustrate the advantages of active learning through a simple example. Suppose U is the unla-

belled distribution:



xi =

e1 ej

w.p.

w.p. 1

1 d2

for j

2

d1 d2

,

{2, * * *

, d} ,

where ej is the standard unit vector in the jth direction. The covariance matrix  of U is a diagonal

matrix with 11 = 1

d1 d2

and jj

=

1 d2

for j

2. For passive learning over U , we query labels

7

of examples drawn from U which active learning chooses to sample
xi =

gives us a examples

fcroonmvetrhgeednicsetrriabtuetioofnTr(msu1ch)

e1 ej

w.p. w.p.

 

1
1
2d

d1
for2dj

, 2

{2, * * *

, d} ,

t=hatmd

.

On

the

other

hand,

where  indicates that the probabilities hold upto O

1 d2

. This has a diagonal covariance matrix

 such that 11  1

d1 2d

and

jj 

1 2d

for

j

2, and convergence rate of

Tr( 1)
m



1 m

2d d+1

*

1

d1 d2

+ (d

1)

*

2d

*

1 d2



4 m

,

which

does

not

grow

with

d!

Logistic Regression. Our second example is logistic regression for binary classification. In this

case, x 2 Rd, Y 2 { 1, 1} and the negative log-likelihood function is: L(y|x, ) = log(1 +

e

y>x),

and

the

corresponding

Fisher

information

I(x, )

is

given

as:

I(x, )

=

e> x (1+e> x )2

*

xx>.

For illustration, suppose kk2 and kxk2 are bounded by a constant and the covariance matrix  is

sandwiched constants c

between and C.

two multiples of identity in the Then the regularity assumptions

P1SDandor2dearirnegsai.teis.,fiedcdI

for

constaCdnIt

for some values of

L1, L2, L3 and L4. In this case, Theorem 1 states that choosing m1 to be ! Tr IU () 1 =

! (d)

gives

us

the

optimal

convergence

rate

of

(1 + o(1)) Tr(I

) . () 1IU ()
m2

Multinomial Logistic Regression. Our third example is multinomial logistic regression for multi-

cTiifnlhafyeossrnm6=celagatasKiostiinv,fiecamanlaotditgorLi-nxl.i(kyiIsenlai=thh(oiKsokd|cxaf,sue1n,))cdYt=io2n(loKi1sg, (.w1.r.i+1,tt)KedPn,mxaKksa=:2t1r1iLxRe,(dywk>,|xxha)ni,cdoh)tthihs=eeropwbatirasaeiy>mn. exedTt+eharselmofcogaolt(lrr1orixew+ssp.oP2nLdKkeRi=tn(F1Kg1

1)d. ek>x), Fisher be the

(K 1)  (K 1) matrix with:

Fii = ei>(x1(+1 +PPk ek6=k>ixe)2k>x) ,

Fij =

ei> x+j> x

(1

+

P
k

ek>x)2

Then, I(x, ) = F  xx>.

Similar to the example in the logistic regression case, suppose y 2 and kxk2 are bounded by

a

constant

and

the

covariance

matrix



satisfies

c d

I



C d

I

for

some

constants

c

and

C.

Since F  = diag (pi ) pp>, where pi = P (y = i|x, ), the boundedness of y 2 and kxk2

implies that ecI F  CeI for some constants ec and Ce (depending on K). This means that

Lcdec4IbeinIg(xc,ons)tantsC. dCTe hIeaonrdemso1thaegariengutelallrsituysatshsautmupstiinogns!1(da)nsda2maprleessaintistfiheedfiwrsitthsteLp1,gLiv2e,sLu3s

and the

optimal convergence rate of maximum likelihood error.

6 Conclusion
In this paper, we provide an active learning algorithm for maximum likelihood estimation which provably achieves the optimal convergence rate (upto lower order terms) and uses only two rounds of interaction. Our algorithm applies in a very general setting, which includes Generalized Linear Models. There are several avenues of future work. Our algorithm involves solving an SDP which is computationally expensive; an open question is whether there is a more efficient, perhaps greedy, algorithm that achieves the same rate. A second open question is whether it is possible to remove the with replacement sampling assumption. A final question is what happens if IU () has a high condition number. In this case, our algorithm will require a large number of samples in the first stage; an open question is whether we can use a more sophisticated procedure in the first stage to reduce the label requirement. Acknowledgements. KC thanks NSF under IIS 1162581 for research support.

8

References
[1] A. Agarwal. Selective sampling algorithms for cost-sensitive multiclass prediction. In Proceedings of the 30th International Conference on Machine Learning, ICML 2013, Atlanta, GA, USA, 16-21 June 2013, pages 1220-1228, 2013.
[2] M.-F. Balcan, A. Beygelzimer, and J. Langford. Agnostic active learning. J. Comput. Syst. Sci., 75(1):78-89, 2009.
[3] M.-F. Balcan and P. M. Long. Active and passive learning of linear separators under logconcave distributions. In COLT, 2013.
[4] A. Beygelzimer, D. Hsu, J. Langford, and T. Zhang. Agnostic active learning without constraints. In NIPS, 2010.
[5] L. Cam and G. Yang. Asymptotics in Statistics: Some Basic Concepts. Springer Series in Statistics. Springer New York, 2000.
[6] J. Cornell. Experiments with Mixtures: Designs, Models, and the Analysis of Mixture Data (third ed.). Wiley, 2002.
[7] S. Dasgupta. Coarse sample complexity bounds for active learning. In NIPS, 2005. [8] S. Dasgupta. Two faces of active learning. Theor. Comput. Sci., 412(19), 2011. [9] S. Dasgupta and D. Hsu. Hierarchical sampling for active learning. In ICML, 2008. [10] S. Dasgupta, D. Hsu, and C. Monteleoni. A general agnostic active learning algorithm. In
NIPS, 2007. [11] R. Frostig, R. Ge, S. M. Kakade, and A. Sidford. Competing with the empirical risk minimizer
in a single pass. arXiv preprint arXiv:1412.6606, 2014. [12] Q. Gu, T. Zhang, C. Ding, and J. Han. Selective labeling via error bound minimization. In In
Proc. of Advances in Neural Information Processing Systems (NIPS) 25, Lake Tahoe, Nevada, United States, 2012. [13] Q. Gu, T. Zhang, and J. Han. Batch-mode active learning via error bound minimization. In 30th Conference on Uncertainty in Artificial Intelligence (UAI), 2014. [14] S. Hanneke. A bound on the label complexity of agnostic active learning. In ICML, 2007. [15] M. Kaariainen. Active learning in the non-realizable case. In ALT, 2006. [16] L. Le Cam. Asymptotic Methods in Statistical Decision Theory. Springer, 1986. [17] E. L. Lehmann and G. Casella. Theory of point estimation, volume 31. Springer Science & Business Media, 1998. [18] R. D. Nowak. The geometry of generalized binary search. IEEE Transactions on Information Theory, 57(12):7893-7906, 2011. [19] S. Sabato and R. Munos. Active regression through stratification. In NIPS, 2014. [20] R. Urner, S. Wulff, and S. Ben-David. Plal: Cluster-based active learning. In COLT, 2013. [21] A. W. van der Vaart. Asymptotic Statistics. Cambridge Series in Statistical and Probabilistic Mathematics. Cambridge University Press, 2000. [22] C. Zhang and K. Chaudhuri. Beyond disagreement-based agnostic active learning. In Proc. of Neural Information Processing Systems, 2014.
9

