Efficient Output Kernel Learning for Multiple Tasks
Pratik Jawanpuria1 , Maksim Lapin2 , Matthias Hein1 and Bernt Schiele2 1 Saarland University, Saarbrucken, Germany
2 Max Planck Institute for Informatics, Saarbrucken, Germany
Abstract
The paradigm of multi-task learning is that one can achieve better generalization by learning tasks jointly and thus exploiting the similarity between the tasks rather than learning them independently of each other. While previously the relationship between tasks had to be user-defined in the form of an output kernel, recent approaches jointly learn the tasks and the output kernel. As the output kernel is a positive semidefinite matrix, the resulting optimization problems are not scalable in the number of tasks as an eigendecomposition is required in each step. Using the theory of positive semidefinite kernels we show in this paper that for a certain class of regularizers on the output kernel, the constraint of being positive semidefinite can be dropped as it is automatically satisfied for the relaxed problem. This leads to an unconstrained dual problem which can be solved efficiently. Experiments on several multi-task and multi-class data sets illustrate the efficacy of our approach in terms of computational efficiency as well as generalization performance.
1 Introduction
Multi-task learning (MTL) advocates sharing relevant information among several related tasks during the training stage. The advantage of MTL over learning tasks independently has been shown theoretically as well as empirically [1, 2, 3, 4, 5, 6, 7].
The focus of this paper is the question how the task relationships can be inferred from the data. It has been noted that naively grouping all the tasks together may be detrimental [8, 9, 10, 11]. In particular, outlier tasks may lead to worse performance. Hence, clustered multi-task learning algorithms [10, 12] aim to learn groups of closely related tasks. The information is then shared only within these clusters of tasks. This corresponds to learning the task covariance matrix, which we denote as the output kernel in this paper. Most of these approaches lead to non-convex problems.
In this work, we focus on the problem of directly learning the output kernel in the multi-task learning framework. The multi-task kernel on input and output is assumed to be decoupled as the product of a scalar kernel and the output kernel, which is a positive semidefinite matrix [1, 13, 14, 15]. In classical multi-task learning algorithms [1, 16], the degree of relatedness between distinct tasks is set to a constant and is optimized as a hyperparameter. However, constant similarity between tasks is a strong assumption and is unlikely to hold in practice. Thus recent approaches have tackled the problem of directly learning the output kernel. [17] solves a multi-task formulation in the framework of vector-valued reproducing kernel Hilbert spaces involving squared loss where they penalize the Frobenius norm of the output kernel as a regularizer. They formulate an invex optimization problem that they solve optimally. In comparison, [18] recently proposed an efficient barrier method to optimize a generic convex output kernel learning formulation. On the other hand, [9] proposes a convex formulation to learn low rank output kernel matrix by enforcing a trace constraint. The above approaches [9, 17, 18] solve the resulting optimization problem via alternate minimization between task parameters and the output kernel. Each step of the alternate minimization requires an eigen-
1

value decomposition of a matrix having as size the number of tasks and a problem corresponding to learning all tasks independently.
In this paper we study a similar formulation as [17]. However, we allow arbitrary convex loss functions and employ general p-norms for p  (1, 2] (including the Frobenius norm) as regularizer for the output kernel. Our problem is jointly convex over the task parameters and the output kernel. Small p leads to sparse output kernels which allows for an easier interpretation of the learned task relationships in the output kernel. Under certain conditions on p we show that one can drop the constraint that the output kernel should be positive definite as it is automatically satisfied for the unconstrained problem. This significantly simplifies the optimization and our result could also be of interest in other areas where one optimizes over the cone of positive definite matrices. The resulting unconstrained dual problem is amenable to efficient optimization methods such as stochastic dual coordinate ascent [19], which scale well to large data sets. Overall we do not require any eigenvalue decomposition operation at any stage of our algorithm and no alternate minimization is necessary, leading to a highly efficient methodology. Furthermore, we show that this trick not only applies to p-norms but also applies to a large class of regularizers for which we provide a characterization.
Our contributions are as follows: (a) we propose a generic p-norm regularized output kernel matrix learning formulation, which can be extended to a large class of regularizers; (b) we show that the constraint on the output kernel to be positive definite can be dropped as it is automatically satisfied, leading to an unconstrained dual problem; (c) we propose an efficient stochastic dual coordinate ascent based method for solving the dual formulation; (d) we empirically demonstrate the superiority of our approach in terms of generalization performance as well as significant reduction in training time compared to other methods learning the output kernel.
The paper is organized as follows. We introduce our formulation in Section 2. Our main technical result is discussed in Section 3. The proposed optimization algorithm is described in Section 4. In Section 5, we report the empirical results. All the proofs can be found in the supplementary material.

2 The Output Kernel Learning Formulation

We first introduce the setting considered in this paper. We denote the number of tasks by T . We
assume that all tasks have a common input space X and a common positive definite kernel function
k : X x X  R. We denote by (*) the feature map and by Hk the reproducing kernel Hilbert space (RKHS) [20] associated with k. The training data is (xi, yi, ti)ni=1, where xi  X , ti is the task the i-th instance belongs to and yi is the corresponding label. Moreover, we have a positive definite matrix   S+T on the set of tasks {1, . . . , T }, where S+T is the set of T x T symmetric and positive semidefinite (p.s.d.) matrices.

If one arranges the predictions of all tasks in a vector one can see multi-task learning as learning a vector-valued function in a RKHS [see 1, 13, 14, 15, 18, and references therein]. However, in this paper we use the one-to-one correspondence between real-valued and matrix-valued kernels, see [21], in order to limit the technical overhead. In this framework we define the joint kernel of input space and the set of tasks M : (X x {1, . . . , T }) x (X x {1, . . . , T })  R as

M (x, s), (z, t) = k(x, z)(s, t),

(1)

We denote the corresponding RKHS of functions on X x {1, . . . , T } as HM and by * HM the corresponding norm. We formulate the output kernel learning problem for multiple tasks as

n
min C L yi, F (xi, ti)
S+T ,F HM i=1

1 +
2

F

2 HM

+

V

()

(2)

where L : R x R  R is the convex loss function (convex in the second argument), V () is a

convex regularizer penalizing the complexity of the output kernel  and   R+ is the regularization

parameter. Note that

F

2 HM

implicitly

depends

also

on

.

In

the

following

we

show

that

(2)

can

be reformulated into a jointly convex problem in the parameters of the prediction function and the

output kernel . Using the standard representer theorem [20] (see the supplementary material) for fixed output kernel , one can show that the optimal solution F   HM of (2) can be written as

Tn

Tn

F (x, t) =

isM (xi, s), (x, t) =

isk(xi, x)(s, t).

(3)

s=1 i=1

s=1 i=1

2

With the explicit form of the prediction function one can rewrite the main problem (2) as

n Tn

1T n

min C L

S+T ,RnxT

i=1

yi, jskjis ti
s=1 j=1

+ 2

irjskij rs +  V (),

r,s=1 i,j=1

(4)

where rs = (r, s) and kij = k(xi, xj). Unfortunately, problem (4) is not jointly convex in 

and  due to the product in the second term. A similar problem has been analyzed in [17]. They

could show that for the squared loss and V () =



2 F

the corresponding optimization problem is

invex and directly optimize it. For an invex function every stationary point is globally optimal [22].

We follow a different path which leads to a formulation similar to the one of [2] used for learning an input mapping (see also [9]). Our formulation for the output kernel learning problem is jointly convex in the task kernel  and the task parameters. We present a derivation for the general RKHS Hk, analogous to the linear case presented in [2, 9]. We use the following variable transformation,

T
it = tsis, i = 1, . . . , n, s = 1, . . . , T,
s=1

resp.

T

is =

-1 stit.

t=1

In the last expression -1 has to be understood as the pseudo-inverse if  is not invertible. Note

that this causes no problems as in case  is not invertible, we can without loss of generality restrict

 in (4) to the range of . The transformation leads to our final problem formulation, where the

prediction function F and its squared norm

F

2 HM

can

be

written

as

n
F (x, t) = itk(xi, x),
i=1

Tn

F

2 HM

=

-1 srisjrk(xi, xj ).

r,s=1 i,j=1

(5)

We get our final primal optimization problem

nn

min C L
S+T ,RnxT i=1

yi, jti kji
j=1

1T n +
2
r,s=1 i,j=1

-1 srisjrkij +  V ()

(6)

Before we analyze the convexity of this problem, we want to illustrate the connection to the formu-

lations in [9, 17]. With the task weight vectors wt =

n j=1

jt(xj )



Hk

we

get

predictions

as

F (x, t) = wt, (x) and one can rewrite

Tn

T

F

2 HM

=

-1 srisjrk(xi, xj ) =

-1 sr ws, wt .

r,s=1 i,j=1

r,s=1

This identity is known for vector-valued RKHS, see [15] and references therein. When  is  times

the identity matrix, then

F

2 HM

=

T t=1

wt 

2

and thus (2) is learning the tasks independently.

As

mentioned before the convexity of the expression of

F

2 HM

is

crucial

for

the

convexity

of

the

full

problem (6). The following result has been shown in [2] (see also [9]).

Lemma 1 Let R() denote the range of   S+T and let  be the pseudoinverse. The extended function f : S+T x RnxT  R  {} defined as

f (, ) =

T r,s=1

n i,j=1

 srisjrk(xi, xj ),

if i*  R(),  i = 1, . . . , n, ,

 else .

is jointly convex.

The formulation in (6) is similar to [9, 17, 18]. [9] uses the constraint Trace()  1 instead of a regularizer V () enforcing low rank of the output kernel. On the other hand, [17] employs squared Frobenius norm for V () with squared loss function. [18] proposed an efficient algorithm for convex V (). Instead we think that sparsity of  is better to avoid the emergence of spurious relations between tasks and also leads to output kernels which are easier to interpret. Thus we propose to use the following regularization functional for the output kernel :

T

V () =

|tt |p =



p p

,

t,t =1

3

for p  [1, 2]. Several approaches [9, 17, 18] employ alternate minimization scheme, involving costly eigendecompositions of T x T matrix per iteration (as   S+T ). In the next section we show that for a certain set of values of p one can derive an unconstrained dual optimization problem which thus avoids the explicit minimization over the S+T cone. The resulting unconstrained dual problem can then be easily optimized by stochastic coordinate ascent. Having explicit expressions of the
primal variables  and  in terms of the dual variables allows us to get back to the original problem.

3 Unconstrained Dual Problem Avoiding Optimization over S+T

The primal formulation (6) is a convex multi-task output kernel learning problem. The next lemma
derives the Fenchel dual function of (6). This still involves the optimization over the primal variable   S+T . A main contribution of this paper is to show that this optimization problem over the S+T cone can be solved with an analytical solution for a certain class of regularizers V (). In the following we denote by r := {i | ti = r} the dual variables corresponding to task r and by Krs the kernel matrix (k(xi, xj) | ti = r, tj = s) corresponding to the dual variables of tasks r and s.

Lemma 2 Let Li be the conjugate function of the loss Li : R  R, u  L(yi, u), then

n
q : Rn  R, q() = -C Li
i=1

- i C

-  max
S+T

1 2

T

rs r, Krss - V ()

r,s=1

(7)

is the dual function of (6), where   Rn are the dual variables. The primal variable   RnxT

in (6) and F (x, s) =

the prediction function F can be expressed

n j=1

j

stj

k(xj

,

x)

respectively,

where

tj

in is

terms of  and  the task of the j-th

as is = isti training example.

and

We now focus on the remaining maximization problem in the dual function in (7)

1T

max
S+T

2

rs
r,s=1

r, Krss

- V ().

(8)

This is a semidefinite program which is computationally expensive to solve and thus prohibits to

scale the output kernel learning problem to a large number of tasks. However, we show in the

following that this problem has an analytical solution for a subset of the regularizers V () =

1 2

T r,s=1

|rs

|p

for

p



1.

For

better

readability

we

defer a

more general result

towards

the

end

of the section. The basic idea is to relax the constraint on   RT xT in (8) so that it is equivalent

to the computation of the conjugate V  of V . If the maximizer of the relaxed problem is positive

semi-definite, one has found the solution of the original problem.

Theorem 3

Let

k



N

and

p

=

2k 2k-1

,

then

with

rs

=

1 2

r, Krss

we have

max
S+T

T
rsrs
r,s=1

-

1 2

T
|rs|p
r,s=1

=

1 4k - 2

2k - 1 2k

2k T r, Krss 2k ,
r,s=1

and the maximizer is given by the positive semi-definite matrix

rs =

2k - 1 2k

2k-1

r, Krss 2k-1 ,

r, s = 1, . . . , T.

(9) (10)

Plugging the result of the previous theorem into the dual function of Lemma 2 we get for k  N and

p

=

2k 2k-1

with

V

()

=



p p

the following unconstrained dual of our main problem (6):

n

max -C
Rn

Li

i=1

- i C

 2k - 1 2k T -
4k - 2 2k

r, Krss 2k .

r,s=1

(11)

Note that by doing the variable transformation i

:=

i C

we effectively have only one hyper-

parameter in (11). This allows us to cross-validate more efficiently. The range of admissible values

for p in Theorem 3 lies in the interval (1, 2], where we get for k = 1 the value p = 2 and as k  

4

Table 1: Examples of regularizers V () together with their generating function  and the explicit

form

of



in

terms

of

the

dual

variables,

rs

=

1 2

r, Krss . The optimal value of (8) is given

in terms of  as max ,  - V () =
RT xT

T r,s=1

(rs

).

(z) V ()

rs

z2k 2k

,

k



N

2k-1 2k

T

|rs

|

2k 2k-1

r,s=1

2rsk-1

ez =

 zk k=0 k!

T  rs log(rs) - rs
r,s=1


if rs > 0r, s else .

ers

cosh(z) - 1 =

 z2k k=1 (2k)!

T
rs arcsinh(rs) - 1 + 2rs + T 2

r,s=1

arcsinh(rs)

we have p  1. The regularizer for p = 2 together with the squared loss has been considered in the primal in [17, 18]. Our analytical expression of the dual is novel and allows us to employ stochastic dual coordinate ascent to solve the involved primal optimization problem. Please also note that by optimizing the dual, we have access to the duality gap and thus a well-defined stopping criterion. This is in contrast to the alternating scheme of [17, 18] for the primal problem which involves costly matrix operations. Our runtime experiments show that our solver for (11) outperforms the solvers of [17, 18]. Finally, note that even for suboptimal dual variables , the corresponding  matrix in (10) is positive semidefinite. Thus we always get a feasible set of primal variables.

Characterizing the set of convex regularizers V which allow an analytic expression for the
dual function The previous theorem raises the question for which class of convex, separable reg-
ularizers we can get an analytical expression of the dual function by explicitly solving the opti-
mization problem (8) over the positive semidefinite cone. A key element in the proof of the previous theorem is the characterization of functions f : R  R which when applied elementwise f (A) = (f (aij))Ti,j=1 to a positive semidefinite matrix A  S+T result in a p.s.d. matrix, that is f (A)  S+T . This set of functions has been characterized by Hiai [23].

Theorem 4 ([23]) Let f : R  R and A  S+T . We denote by f (A) = (f (aij))Ti,j=1 the element-

wise application of f to A. It holds  T  2, A  S+T = f (A)  S+T if and only if f is analytic

and f (x) =

 k=0

ak xk

with

ak



0

for

all

k



0.

Note that in the previous theorem the condition on f is only necessary when we require the implication to hold for all T . If T is fixed, the set of functions is larger and includes even (large) fractional powers, see [24]. We use the stronger formulation as we want that the result holds without any restriction on the number of tasks T . Theorem 4 is the key element used in our following characterization of separable regularizers of  which allow an analytical expression of the dual function.

Theorem 5 Let  : R  R be analytic on R and given as (z) =

 k=0

ak k+1

zk+1

where

ak



0 k  0. If  is convex, then, V () :=

T r,s=1

(rs

),

is

a

convex

function

V

: RT xT

 R and

T

max ,  - V () = V () =

 rs ,

RT xT

r,s=1

where the global maximizer fulfills   S+T if   S+T and rs =

 k=0

ak

krs

.

(12)

Table 1 summarizes e.g. of functions , the corresponding V () and the maximizer  in (12).

4 Optimization Algorithm
The dual problem (11) can be efficiently solved via decomposition based methods like stochastic dual coordinate ascent algorithm (SDCA) [19]. SDCA enjoys low computational complexity per iteration and has been shown to scale effortlessly to large scale optimization problems.

5

Algorithm 1 Fast MTL-SDCA
Input: Gram matrix K, label vector y, regularization parameter and relative duality gap parameter Output:  ( is computed from  using our result in 10) Initialize  = (0) repeat
Randomly choose a dual variable i Solve for  in (13) corresponding to i i  i +  until Relative duality gap is below

Our algorithm for learning the output kernel matrix and task parameters is summarized in Algo-
rithm 1 (refer to the supplementary material for more details). At each step of the iteration we opti-
mize the dual objective over a randomly chosen i variable. Let ti = r be the task corresponding to i. We apply the update i  i + . The optimization problem of solving (11) with respect to  is as follows:

min
R

Li

(-i - )/C

+  (a2 + 2brr + crr)2k + 2

(brs + crs)2k +

c2szk , (13)

s=r

s,z=r

2k

where a = kii, brs =

j:tj=s kij j s, csz = s, Kszz

s, z and 

=

 C (4k-2)

2k-1 2k

.

This one-dimensional convex optimization problem is solved efficiently via Newton method. The

complexity of the proposed algorithm is O(T ) per iteration . The proposed algorithm can also be

employed for learning output kernels regularized by generic V (), discussed in the previous section.

Special case p = 2(k = 1): For certain loss functions such as the hinge loss, the squared loss, etc.,

Lti

-

ti + C

yields a linear or a quadratic expression in . In such cases problem (13) reduces to

finding the roots of a cubic equation, which has a closed form expression. Hence, our algorithm is

highly efficient with the above loss functions when  is regularized by the squared Frobenius norm.

5 Empirical Results
In this section, we present our results on benchmark data sets comparing our algorithm with existing approaches in terms of generalization accuracy as well as computational efficiency. Please refer to the supplementary material for additional results and details.
5.1 Multi-Task Data Sets
We begin with the generalization results in multi-task setups. The data sets are as follows: a) Sarcos: a regression data set, aim is to predict 7 degrees of freedom of a robotic arm, b) Parkinson: a regression data set, aim is to predict the Parkinson's disease symptom score for 42 patients, c) Yale: a face recognition data with 28 binary classification tasks, d) Landmine: a data set containing binary classifications from 19 different landmines, e) MHC-I: a bioinformatics data set having 10 binary classification tasks, f) Letter: a handwritten letters data set with 9 binary classification tasks. We compare the following algorithms: Single task learning (STL), multi-task methods learning the output kernel matrix (MTL [16], CMTL [12], MTRL [9]) and approaches that learn both input and output kernel matrices (MTFL [11], GMTL [10]). Our proposed formulation (11) is denoted by FMTLp. We consider three different values for the p-norm: p = 2 (k = 1), p = 4/3 (k = 2) and p = 8/7 (k = 4). Hinge and -SVR loss functions were employed for classification and regression problems respectively. We follow the experimental protocol1 described in [11].
Table 2 reports the performance of the algorithms averaged over ten random train-test splits. The proposed FMTLp attains the best generalization accuracy in general. It outperforms the baseline MTL as well as MTRL and CMTL, which solely learns the output kernel matrix. Moreover, it achieves an overall better performance than GMTL and MTFL. The FMTLp=4/3,8/7 give comparable generalization to p = 2 case, with the additional benefit of learning sparser and more interpretable output kernel matrix (see Figure 1).
1The performance of STL, MTL, CMTL and MTFL are reported from [11].

6

Table 2: Mean generalization performance and the standard deviation over ten train-test splits.

Data set

STL

MTL

CMTL

MTFL

GMTL

MTRL

p=2

FMTLp p = 4/3 p = 8/7

Regression data sets: Explained Variance (%)
Sarcos 40.57.6 34.510.2 33.013.4 49.96.3 45.810.6 41.67.1 46.76.9 50.35.8 48.45.8 Parkinson 2.87.5 4.920.0 2.73.6 16.810.8 33.69.4 12.06.8 27.04.4 27.04.4 27.04.4

Classification data sets: AUC (%)
Yale 93.42.3 96.41.6 Landmine 74.61.6 76.40.8 MHC-I 69.32.1 72.31.9 Letter 61.20.8 61.01.6

95.22.1 75.90.7 72.61.4 60.51.1

97.01.6 76.41.0 71.72.2 60.51.8

91.93.2 76.71.2 72.52.7 61.20.9

96.12.1 76.11.0 71.51.7 60.31.4

97.01.2 76.80.8 71.71.9 61.40.7

97.01.4 76.71.0 70.82.1 61.51.0

96.81.4 76.40.9 70.71.9 61.41.0

2 4 6 8 10 12 14 16 18
2 4 6 8 10 12 14 16 18
(p = 2)

2 4 6 8 10 12 14 16 18
2 4 6 8 10 12 14 16 18
(p = 4/3)

2 4 6 8 10 12 14 16 18
2 4 6 8 10 12 14 16 18
(p = 8/7)

Figure 1: Plots of || matrices (rescaled to [0,1] and averaged over ten splits) computed by our solver FMTLp for the Landmine data set for different p-norms, with cross-validated hyper-parameter values. The darker regions indicate higher value. Tasks (landmines) numbered 1-10 correspond to highly foliated regions and those numbered 11-19 correspond to bare earth or desert regions. Hence, we expect two groups of tasks (indicated by the red squares). We can observe that the learned  matrix at p = 2 depicts much more spurious task relationships than the ones at p = 4/3 and p = 8/7. Thus, our sparsifying regularizer improves interpretability.

Data set

Table 3: Mean accuracy and the standard deviation over five train-test splits.

STL MTL-SDCA GMTL MTRL

FMTLp -H p = 2 p = 4/3 p = 8/7

FMTLp -S p = 2 p = 4/3 p = 8/7

MNIST 84.10.3 86.00.2 84.80.3 85.60.4 86.10.4 85.80.4 86.20.4 82.20.6 82.50.4 82.40.3 USPS 90.50.3 90.60.2 91.60.3 92.40.2 92.40.2 92.60.2 92.60.1 87.20.4 87.70.3 87.50.3

5.2 Multi-Class Data Sets
The multi-class setup is cast as T one-vs-all binary classification tasks, corresponding to T classes. In this section we experimented with two loss functions: a) FMTLp-H - the hinge loss employed in SVMs, and b) FMTLp-S - the squared loss employed in OKL [17]. In these experiments, we also compare our results with MTL-SDCA, a state-of-the-art multi-task feature learning method [25].
USPS & MNIST Experiments: We followed the experimental protocol detailed in [10]. Results are tabulated in Table 3. Our approach FMTLp-H obtains better accuracy than GMTL, MTRL and MTL-SDCA [25] on both data sets.
MIT Indoor67 Experiments: We report results on the MIT Indoor67 benchmark [26] which covers 67 indoor scene categories. We use the train/test split (80/20 images per class) provided by the authors. FMTLp-S achieved the accuracy of 73.3% with p = 8/7. Note that this is better than the ones reported in [27] (70.1%) and [26] (68.24%).
SUN397 Experiments: SUN397 [28] is a challenging scene classification benchmark [26] with 397 classes. We use m = 5, 50 images per class for training, 50 images per class for testing and report the average accuracy over the 10 standard splits. We employed the CNN features extracted with the
7

Table 4: Mean accuracy and the standard deviation over ten train-test splits on SUN397.

m STL

MTL

MTL-SDCA

p=2

FMTLp -H p = 4/3 p = 8/7

p=2

FMTLp -S p = 4/3 p = 8/7

5 40.50.9 42.01.4 41.21.3 41.51.1 41.61.3 41.61.2 44.11.3 44.11.1 44.01.2 50 55.00.4 57.00.2 54.80.3 55.10.2 55.60.3 55.10.3 58.60.1 58.50.1 58.60.2

Time (log scale), s
10
(Time by baseline) / (Time by FMTL -S)
2

103
FMTL2-S
102 ConvexOKL
OKL
101

100

10-1

10-2 50

100 150 200 250 300 350 400 Number of Tasks
(a)

20

MIT Indoor67, OKL
18 SUN397, OKL

16

MIT Indoor67, ConvexOKL . SUN397, ConvexOKL

14

12

10

8

6

4

2

0 3 3.5 4 4.5 5 5.5 6 6.5 7
Log10()

(b)

Figure 2: (a) Plot compares the runtime of various algorithms with varying number of tasks on SUN397. Our approach FMTL2-S is 7 times faster that OKL [17] and 4.3 times faster than ConvexOKL [18] when the number of tasks is maximum. (b) Plot showing the factor by which FMTL2S outperforms OKL and ConvexOKL over the hyper-parameter range on various data sets. On SUN397, we outperform OKL and ConvexOKL by factors of 5.2 and 7 respectively. On MIT Indoor67, we are better than OKL and ConvexOKL by factors of 8.4 and 2.4 respectively.

convolutional neural network (CNN) [26] using Places 205 database. The results are tabulated in Table 4. The  matrices computed by FMTLp-S are discussed in the supplementary material.
5.3 Scaling Experiment
We compare the runtime of our solver for FMTL2-S with the OKL solver of [17] and the ConvexOKL solver of [18] on several data sets. All the three methods solve the same optimization problem. Figure 2a shows the result of the scaling experiment where we vary the number of tasks (classes). The parameters employed are the ones obtained via cross-validation. Note that both OKL and ConvexOKL algorithms do not have a well defined stopping criterion whereas our approach can easily compute the relative duality gap (set as 10-3). We terminate them when they reach the primal objective value achieved by FMTL2-S . Our optimization approach is 7 times and 4.3 times faster than the alternate minimization based OKL and ConvexOKL, respectively, when the number of tasks is maximal. The generic FMTLp=4/3,8/7 are also considerably faster than OKL and ConvexOKL.
Figure 2b compares the average runtime of our FMTLp-S with OKL and ConvexOKL on the crossvalidated range of hyper-parameter values. FMTLp-S outperform them on both MIT Indoor67 and SUN397 data sets. On MNIST and USPS data sets, FMTLp-S is more than 25 times faster than OKL, and more than 6 times faster than ConvexOKL. Additional details of the above experiments are discussed in the supplementary material.
6 Conclusion
We proposed a novel formulation for learning the positive semi-definite output kernel matrix for multiple tasks. Our main technical contribution is our analysis of a certain class of regularizers on the output kernel matrix where one may drop the positive semi-definite constraint from the optimization problem, but still solve the problem optimally. This leads to a dual formulation that can be efficiently solved using stochastic dual coordinate ascent algorithm. Results on benchmark multi-task and multi-class data sets demonstrates the effectiveness of the proposed multi-task algorithm in terms of runtime as well as generalization accuracy.
Acknowledgments. P.J. and M.H. acknowledge the support by the Cluster of Excellence (MMCI).

8

References
[1] T. Evgeniou, C. A. Micchelli, and M. Pontil. Learning multiple tasks with kernel methods. JMLR, 6:615-637, 2005.
[2] A. Argyriou, T. Evgeniou, and M. Pontil. Convex multi-task feature learning. ML, 73:243-272, 2008.
[3] K. Lounici, M. Pontil, A. B. Tsybakov, and S. van de Geer. Taking advantage of sparsity in multi-task learning. In COLT, 2009.
[4] A. Jalali, P. Ravikumar, S. Sanghavi, and C. Ruan. A dirty model for multi-task learning. In NIPS, 2010.
[5] P. Jawanpuria and J. S. Nath. Multi-task multiple kernel learning. In SDM, 2011.
[6] A. Maurer, M. Pontil, and B. Romera-paredes. Sparse coding for multitask and transfer learning. In ICML, 2013.
[7] P. Jawanpuria, J. S. Nath, and G. Ramakrishnan. Generalized hierarchical kernel learning. JMLR, 16:617- 652, 2015.
[8] R. Caruana. Multitask learning. ML, 28:41-75, 1997.
[9] Y. Zhang and D. Y. Yeung. A convex formulation for learning task relationships in multi-task learning. In UAI, 2010.
[10] Z. Kang, K. Grauman, and F. Sha. Learning with whom to share in multi-task feature learning. In ICML, 2011.
[11] P. Jawanpuria and J. S. Nath. A convex feature learning formulation for latent task structure discovery. In ICML, 2012.
[12] L. Jacob, F. Bach, and J. P. Vert. Clustered multi-task learning: A convex formulation. In NIPS, 2008.
[13] C. A. Micchelli and M. Pontil. Kernels for multitask learning. In NIPS, 2005.
[14] A. Caponnetto, C. A. Micchelli, M. Pontil, and Y. Ying. Universal multi-task kernels. JMLR, 9:1615- 1646, 2008.
[15] M. A. A lvarez, L. Rosasco, and N. D. Lawrence. Kernels for vector-valued functions: a review. Foundations and Trends in Machine Learning, 4:195-266, 2012.
[16] T. Evgeniou and M. Pontil. Regularized multi-task learning. In KDD, 2004.
[17] F. Dinuzzo, C. S. Ong, P. Gehler, and G. Pillonetto. Learning output kernels with block coordinate descent. In ICML, 2011.
[18] C. Ciliberto, Y. Mroueh, T. Poggio, and L. Rosasco. Convex learning of multiple tasks and their structure. In ICML, 2015.
[19] S. Shalev-Shwartz and T. Zhang. Stochastic dual coordinate ascent methods for regularized loss. JMLR, 14(1):567-599, 2013.
[20] B. Scholkopf and A. Smola. Learning with Kernels. MIT Press, 2002.
[21] M. Hein and O. Bousquet. Kernels, associated structures and generalizations. Technical Report TR-127, Max Planck Institute for Biological Cybernetics, 2004.
[22] A. Ben-Israel and B. Mond. What is invexity ? J. Austral. Math. Soc. Ser. B, 28:1-9, 1986.
[23] F. Hiai. Monotonicity for entrywise functions of matrices. Linear Algebra and its Applications, 431(8):1125 - 1146, 2009.
[24] R. A. Horn. The theory of infinitely divisible matrices and kernels. Trans. Amer. Math. Soc., 136:269-286, 1969.
[25] M. Lapin, B. Schiele, and M. Hein. Scalable multitask representation learning for scene classification. In CVPR, 2014.
[26] B. Zhou, A. Lapedriza, J. Xiao, A. Torralba, and A. Oliva. Learning deep features for scene recognition using places database. In NIPS, 2014.
[27] M. Koskela and J. Laaksonen. Convolutional network features for scene recognition. In Proceedings of the ACM International Conference on Multimedia, 2014.
[28] J. Xiao, J. Hays, K. A. Ehinger, A. Oliva, and A. Torralba. SUN database: Large-scale scene recognition from abbey to zoo. In CVPR, 2010.
9

