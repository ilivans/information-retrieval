Improved Iteration Complexity Bounds of Cyclic Block Coordinate Descent for Convex Problems

Ruoyu Sun, Mingyi Hong 
Abstract
The iteration complexity of the block-coordinate descent (BCD) type algorithm has been under extensive investigation. It was recently shown that for convex problems the classical cyclic BCGD (block coordinate gradient descent) achieves an O(1/r) complexity (r is the number of passes of all blocks). However, such bounds are at least linearly depend on K (the number of variable blocks), and are at least K times worse than those of the gradient descent (GD) and proximal gradient (PG) methods. In this paper, we close such theoretical performance gap between cyclic BCD and GD/PG. First we show that for a family of quadratic nonsmooth problems, the complexity bounds for cyclic Block Coordinate Proximal Gradient (BCPG), a popular variant of BCD, can match those of the GD/PG in terms of dependency on K (up to a log2(K) factor). Second, we establish an improved complexity bound for Coordinate Gradient Descent (CGD) for general convex problems which can match that of GD in certain scenarios. Our bounds are sharper than the known bounds as they are always at least K times worse than GD. Our analyses do not depend on the update order of block variables inside each cycle, thus our results also apply to BCD methods with random permutation (random sampling without replacement, another popular variant).

1 Introduction
Consider the following convex optimization problem

K
min f (x) = g(x1, * * * , xK ) + hk(xk), s.t. xk  Xk,  k = 1, * * * K,
k=1

(1)

where g : X  R is a convex smooth function; h : X  R is a convex lower semi-continuous possibly nonsmooth function; xk  Xk  RN is a block variable. A very popular method for solving this problem is the so-called block coordinate descent (BCD) method [5], where each time a single block variable is optimized while the rest of the variables remain fixed. Using the classical cyclic block selection rule, the BCD method can be described below.

Algorithm 1: The Cyclic Block Coordinate Descent (BCD) At each iteration r + 1, update the variable blocks by:

x(kr)



min
xk Xk

g

xk , w-(rk)

+ hk(xk), k = 1, * * * , K.

(2)

Department of Management Science and Engineering, Stanford University, Stanford, CA. ruoyu@stanford.edu
Department of Industrial & Manufacturing Systems Engineering and Department of Electrical & Computer Engineering, Iowa State University, Ames, IA, mingyi@iastate.edu
The authors contribute equally to this work.
1

where we have used the following short-handed notations:

wk(r) := x(1r), * * * , x(kr-)1, x(kr-1), x(kr+-11), * * * , x(Kr-1) , k = 1, * * * , K,
w-(rk) := x(1r), * * * , x(kr-)1, x(kr+-11), * * * , x(Kr-1) , k = 1, * * * , K,
x-k := [x1, * * * , xk-1, xk+1, * * * , xK ] .
The convergence analysis of the BCD has been extensively studied in the literature, see [5, 14, 19, 15, 4, 7, 6, 10, 20]. For example it is known that for smooth problems (i.e. f is continuous differentiable but possibly nonconvex, h = 0), if each subproblem has a unique solution and g is non-decreasing in the interval between the current iterate and the minimizer of the subproblem (one special case is per-block strict convexity), then every limit point of {x(r)} is a stationary point [5, Proposition 2.7.1]. The authors of [6, 19] have derived relaxed conditions on the convergence of BCD. In particular, when problem (1) is convex and the level sets are compact, the convergence of the BCD is guaranteed without requiring the subproblems to have unique solutions [6]. Recently Razaviyayn et al [15] have shown that the BCD converges if each subproblem (2) is solved inexactly, by way of optimizing certain surrogate functions.
Luo and Tseng in [10] have shown that when problem (1) satisfies certain additional assumptions such as having a smooth composite objective and a polyhedral feasible set, then BCD converges linearly without requiring the objective to be strongly convex. There are many recent works on showing iteration complexity for randomized BCGD (block coordinate gradient descent), see [17, 12, 8, 16, 9] and the references therein. However the results on the classical cyclic BCD is rather scant. Saha and Tewari [18] show that the cyclic BCD achieves sublinear convergence for a family of special LASSO problems. Nutini et al [13] show that when the problem is strongly convex, unconstrained and smooth, BCGD with certain Gauss-Southwell block selection rule could be faster than the randomized rule. Recently Beck and Tetruashvili show that cyclic BCGD converges sublinearly if the objective is smooth. Subsequently Hong et al in [7] show that such sublinear rate not only can be extended to problems with nonsmooth objective, but is true for a large family of BCD-type algorithm (with or without per-block exact minimization, which includes BCGD as a special case). When each block is minimized exactly and when there is no per-block strong convexity, Beck [2] proves the sublinear convergence for certain 2-block convex problem (with only one block having Lipschitzian gradient). It is worth mentioning that all the above results on cyclic BCD can be used to prove the complexity for a popular randomly permuted BCD in which the blocks are randomly sampled without replacement.
To illustrate the rates developed for the cyclic BCD algorithm, let us define X to be the optimal solution set for problem (1), and define the constant

R0

:=

max
xX

max
x X 

x - x | f (x)  f (x(0)) .

(3)

Let us assume that hk(xk)  0, Xk = RN ,  k for now, and assume that g(*) has Lipschitz continuous gradient:

g(x) - g(z)  L x - z ,  x, z  X.

(4)

Also assume that g(*, x-k) has Lipschitz continuous gradient with respect to each xk, i.e.,

kg(xk, x-k) - kg(vk, x-k)  Lk xk - vk ,  x, v  X,  k.

(5)

Let Lmax := maxk Lk and Lmin := mink Lk. It is known that the cyclic BCPG has the following iteration complexity [4, 7] 1

(BrC) D

:=

f (x(r))

-

f



C Lmax (1

+

K

L2/L2min)R02

1 r

,

 r  1,

(6)

where C > 0 is some constant independent of problem dimension. Similar bounds are provided for cyclic BCD in [7, Theorem 6.1]. In contrast, it is well known that when applying the classical

1Note that the assumptions made in [4] and [7] are slightly different, but the rates derived in both cases have similar dependency on the problem dimension K.

2

gradient descent (GD) method to problem (1) with the constant stepsize 1/L, we have the following rate estimate [11, Corollary 2.1.2]

(GrD) := f (x(r)) - f (x) 

2

x(0) - x r+4

2L



2R02L r+4

,

 r  1,  x  X.

(7)

Note that unlike (6), here the constant in front of the 1/(r + 4) term is independent of the problem dimension. In fact, the ratio of the bound given in (6) and (7) is

C

Lmax L

(1

+

K

L2/L2min)

r

+ r

4

which is at least in the order of K. For big data related problems with over millions of variables, a multiplicative constant in the order of K can be a serious issue. In a recent work by Saha and Tewari [18], the authors show that for a LASSO problem with special data matrix, the rate of cyclic BCD (with special initialization) is indeed K-independent. Unfortunately, such a result has not yet been extended to any other convex problems. An open question posed by a few authors [4, 3, 18] are: is such a K factor gap intrinsic to the cyclic BCD or merely an artifact of the existing analysis?

2 Improved Bounds of Cyclic BCPG for Nonsmooth Quadratic Problem

In this section, we consider the following nonsmooth quadratic problem

1K

2K

min f (x) := 2

Akxk - b + hk(xk),

k=1

k=1

s.t. xk  Xk,  k

(8)

where Ak  RMxN ; b  RM ; xk  RN is the kth block coordinate; hk(*) is the same as in
(1). Note the blocks are assumed to have equal dimension for simplicity of presentation. Define A := [A1, * * * , Ak]  RMxKN . For simplicity, we have assumed that all the blocks have the same size. Problem (8) includes for example LASSO and group LASSO as special cases.

We consider the following cyclic BCPG algorithm.

Algorithm 2: The Cyclic Block Coordinate Proximal Gradient (BCPG) At each iteration r + 1, update the variable blocks by:

x(kr+1)

=

arg

min
xk Xk

g(wk(r+1)) +

k g

wk(r+1)

, xk - x(kr)

+ Pk 2

xk - x(kr)

2
+ hk(xk)

(9)

Here Pk is the inverse of the stepsize for xk, which satisfies

Pk  max ATk Ak = Lk,  k.

(10)

Define Pmax := maxk Pk and Pmin = mink Pk. Note that for the least square problem (smooth quadratic minimization, i.e. hk  0,  k), BCPG reduces to the widely used BCGD method.

The optimality condition for the kth subproblem is given by

kg(wk(r+1)) + Pk(x(kr+1) - x(kr)), xk - x(kr+1) + hk(xk) - hk(x(kr+1))  0,  xk  Xk. (11)

In what follows we show that the cyclic BCPG for problem (8) achieves a complexity bound that only dependents on log2(N K), and apart from such log factor it is at least K times better than those
known in the literature. Our analysis consists of the following three main steps:

1. Estimate the descent of the objective after each BCPG iteration; 2. Estimate the cost yet to be minimized (cost-to-go) after each BCPG iteration; 3. Combine the above two estimates to obtain the final bound.

First we show that the BCPG achieves the sufficient descent.

3

Lemma 2.1. We have the following estimate of the descent when using the BCPG:

f (x(r)) - f (x(r+1)) 

K

Pk 2

x(kr+1) - x(kr) 2.

k=1

(12)

Proof. We have the following series of inequalities

f (x(r)) - f (x(r+1))

K
= f (wk(r+1)) - f (wk(r++11))
k=1

K
 f (wk(r+1))- g(wk(r+1)) + hk(x(kr+1)) + k g(wk(r+1)), x(kr+1) - x(kr)
k=1

+ Pk 2

x(kr+1) - x(kr) 2

K
= hk(x(kr)) - hk(x(kr+1)) -
k=1

k g

wk(r+1)

, x(kr+1) - x(kr)

+ Pk 2

x(kr+1) - x(kr) 2



K

Pk 2

x(kr+1) - x(kr) 2.

k=1

where the second inequality uses the optimality condition (11).

Q.E.D.

To proceed, let us introduce two matrices P and A given below, which have dimension K x K and

M K x N K, respectively

 P1 0 0 * * * 0 0 

 A1 0 0 * * * 0 0 

P

:= 

0 ...

P2 0 * * * 0 0 ... ... * * * ... ...

 ,

A := 

0 ...

A2 0 * * * 0 0 ... ... * * * ... ...

 .

0 0 0 * * * 0 PK

0 0 0 * * * 0 AK

By utilizing the definition of Pk in (10) we have the following inequalities (the second inequality comes from [12, Lemma 1])

P  IN

TT
A A, KA A

AT A

(13)

where IN is the N x N identity matrix and the notation "" denotes the Kronecker product.

Next let us estimate the cost-to-go. Lemma 2.2. We have the following estimate of the optimality gap when using the BCPG:
(r+1) : = f (x(r+1)) - f (x)

 R0log(2N K) L/ Pmin + Pmax (x(r+1) - x(r))(P 1/2  IN )

(14)

Our third step combines the previous two steps and characterizes the iteration complexity. This is the main result of this section.
Theorem 2.1. The iteration complexity of using BCPG to solve (8) is given below.

1. When the stepsizes are chosen conservatively as Pk = L,  k, we have

(r+1)  3 max

0, 4 log2(2N K)L

R02 r+1

(15)

2. When the stepsizes are chosen as Pk = max(ATk Ak) = Lk,  k. Then we have

(r+1)  3 max

0, 2 log2(2N K)

L2 Lmax + Lmin

R02 r+1

(16)

In particular, if the problem is smooth and unconstrained, i.e., when h  0, and Xk = RN ,  k, then we have

(r+1)  3 max

L, 2 log2(2N K)

Lmax

+

L2 Lmin

R02 . r+1

(17)

4

We comment on the bounds derived in the above theorem. The bound for BCPG with uniform "conservative" stepsize 1/L has the same order as the GD method, except for the log2(2N K) factor (cf. (7)). In [4, Corollary 3.2], it is shown that the BCGD with the same "conservative" stepsize achieves a sublinear rate with a constant of 4L(1 + K)R02, which is about K/(3 log2(2N K)) times worse than our bound. Further, our bound has the same dependency on L (i.e., 12L v.s. L/2) as the one derived in [18] for BCPG with a "conservative" stepsize to solve an 1 penalized quadratic problem with special data matrix, but our bound holds true for a much larger class of problems (i.e., all quadratic nonsmooth problem in the form of (8)). However, in practice such conservative stepsize is slow (compared with BCPG with Pk = Lk, for all k) hence is rarely used.
The rest of the bounds derived in Theorem 2.1 is again at least K/ log2(2N K) times better than existing bounds of cyclic BCPG. For example, when the problem is smooth and unconstrained, the ratio between our bound (17) and the bound (6) is given by

6R02 log2(2N K)(L2/Lmin + Lmax) CLmax(1 + KL2/L2min)R02



6 log2(2N K)(1 + L2/(LminLmax)) C(1 + KL2/L2min)

=

O(log2(2N K)/K)

(18)

where in the last inequality we have used the fact that Lmax/Lmin  1.
For unconstrained smooth problems, let us compare the bound derived in the second part of Theorem 2.1 (stepsize Pk = Lk, k) with that of the GD (7). If L = KLk for all k (problem badly conditioned), our bound is about K log2(2N K) times worse than that of the GD. This indicates a counter-intuitive phenomenon: by choosing conservative stepsize Pk = L, k the iteration complexity of BCGD is K times better compared with choosing a more aggressive stepzise Pk = Lk, k. It also indicates that the factor L/Lmin may hide an additional factor of K.

3 Iteration Complexity for General Convex Problems

In this section, we consider improved iteration complexity bounds of BCD for general unconstrained

smooth convex problems. We prove a general iteration complexity result, which includes a result of

Beck et al. [4] as a special case. Our analysis for the general case also applies to smooth quadratic

problems, but is very different from the analysis in previous sections for quadratic problems. For simplicity, we only consider the case N = 1 (scalar blocks); the generalization to the case N > 1 is

left as future work.

Let us assume that the smooth objective g has second order derivatives Hij(x)

:=

2g xixj

(x).

When each block is just a coordinate, we assume |Hij(x)|  Lij, i, j. Then Li = Lii and Lij  Li Lj. For unconstrained smooth convex problems with scalar block variables, the BCPG

iteration reduces to the following coordinate gradient descent (CGD) iteration:

x(r) = w1(r) -d1 w2(r) -d2 w3(r) - . . . -dK wK(r+) 1 = x(r+1),

(19)

where dk = kg(wk(r)) and wk(r) -dk wk(r+)1 means that wk(r+)1 is a linear combination of wk(r) and dkek (ek is the k-th block unit vector).

In the following theorem, we provide an iteration complexity bound for the general convex problem. The proof framework follows the standard three-step approach that combines sufficient descent and cost-to-go estimate; nevertheless, the analysis of the sufficient descent is very different from the methods used in the previous sections. The intuition is that CGD can be viewed as an inexact gradient descent method, thus the amount of descent can be bounded in terms of the norm of the full gradient. It would be difficult to further tighten this bound if the goal is to obtain a sufficient descent based on the norm of the full gradient. Having established the sufficient descent in terms of the full gradient g(x(r)), we can easily prove the iteration complexity result, following the standard analysis of GD (see, e.g. [11, Theorem 2.1.13]).

Theorem 3.1. For CGD with Pk  Lmax, k, we have

g(x(r)) - g(x)  2

Pmax +

min{KL2, ( Pmin

k Lk)2}

R02 ,  r  1. r

(20)

5

Proof. Since wkr+1 and wkr only differ by the k-th block, and kg is Lipschitz continuous with Lipschitz constant Lk, we have 2

g(wkr+1) g(wkr ) +

kg(wkr ), wkr+1 - wkr

+ Lk 2

wkr+1 - wkr

2

=g(wkr )

-

2Pk - Lk 2Pk2

kg(wkr )

2

g(wkr )

-

1 2Pk

kg(wkr ) 2,

(21)

where the last inequality is due to Pk  Lk.

The amount of decrease can be estimated as

g (xr )

-

g(xr+1)

=

r
[g(wkr )
k=1

-

g(wkr+1)]



r k=1

1 2Pk

kg(wkr ) 2.

(22)

Since

wkr = xr -

1 P1

d1,

.

.

.

,

1 Pk-1

dk-1 ,

0,

.

.

.

,

0

T
,

by the mean-value theorem, there must exist k such that

kg(xr) - kg(wkr ) = (kg)(k) * (xr - wkr )

=

2g xkx1

(k ),

.

.

.

,

2g xkxk-1

(k ),

0,

.

.

.

,

0

1 P1

d1,

.

.

.

,

1 Pk-1

dk-1,

0,

.

.

.

,

0

T

=

1 P1

Hk1(k),

.

.

.

,

1 Pk-1

Hk,k-1 (k ),

0,

.

.

.

,

0

1 P1

d1,

.

.

.

,

1 PK

dK

T
,

where

Hij (x)

=

2g xixj

(x)

is

the

second

order

derivative

of

g.

Then

kg(xr) = kg(xr) - kg(wkr ) + kg(wkr )

=

1 P1

Hk1 (k ),

.

.

.

,

1 Pk-1

Hk,k-1(k),

0,

.

.

.

,

0

1 P1

d1,

.

.

.

,

1 PK

dK

T
+ dk

=

1 P1

Hk1 (k ),

.

.

.

,

1 Pk-1

Hk,k-1(k),

 Pk ,

0,

.

.

.

,

0

1 P1

d1,

.

.

.

,

1 PK

dK

T

= vkT d,

(23) (24)

where we have defined

d :=

1 P1

d1,

.

.

.

,

1 PK

dK

T
,

11

vk :=

 P1

Hk1(k

),

.

.

.

,

Pk-1 Hk,k-1(k),

Pk, . . . , 0 .

(25)

Let

 P1

V

:=

v1T  . . .
vKT

=



1 1P1
P1

H21 H31

(2) (3)

1 P1

H41

(4)

...

1 P1

HK1

(K

)

0 P2

1 P2

H32

(3

)

1 P2

H42

(4

)

...

1 P2

HK2

(K

)

0 0
P3

1 P3

H43

(4

)

...

1 P3

HK3

(K

)

... ... ...
... ... ...

0 0
0

0

...

1 PK

-1

HK,K-1

(K

)

0

0 0
0  ...



PK

(26)

2

A

stronger

bound

is

g(wkr+1)



g(wkr )

-

1 2Pk

kg(wkr) 2, where Pk =

Pk2 2Pk -Lk

 Pk, but since

Pk  2Pk - Lk  2Pk, the improvement ratio of using this stronger bound is no more than a factor of 2.

6

Therefore, we have

g(xr) 2 =
k

kg(xr) 2 (=24)
k

vkT d 2 =

Vd 2 

V

2 d 2=

V

2

k

1 Pk

kg(wkr ) 2.

Combining with (22), we get

g(xr) - g(xr+1) 

k

1 2Pk

kg(wkr )

2

2

1 V

2

g(xr) 2.

(27)

Let D

Diag(P1, . . . , PK ) and let H() be defined as

0

0

0 ...

0 0

H ( )

:=



H21 (2 ) H31 (3 )
...

0 H32 (3 )
...

0 ... 0 ... ... ...

0 0
...

00...  .

HK1(K ) HK2(K ) HK3(K ) . . . HK,K-1(K ) 0

(28)

Then V = D1/2 + H()D-1/2, which implies

V 2=

D1/2 + H()D-1/2 2  2( D1/2 2 + H()D-1/2 2)  2

Pmax +

H() 2 Pmin

.

Plugging into (27), we obtain

g(x(r)) - g(x(r+1))



1 2

Pmax

1 +

H() Pmin

2

g(x(r)) 2.

(29)

From the fact that Hkj(k) is a scalar bounded above by |Hkj (k)|  Lkj  LkLj, thus

H 2

H

2 F

=

|Hkj (k)|2 

LkLj  ( Lk)2.

k<j k<j k

(30)

We provide the second bound of H below. Let Hk denote the k-th row of H, then Hk  L. Therefore, we have

H 2

H

2 F

=

Hk 2  L2 = KL2.

kk

Combining this bound and (30), we obtain that H 2  min{KL2, ( k Lk)2} 2.

Denote



=

11

2

Pmax +

2 Pmin

,

then

(29)

becomes

g(x(r)) - g(x(r+1))   g(x(r)) 2, r.

(31)

This relation also implies g(x(r))  g(x(0)), thus by the definition of R0 in (3) we have x(r) - x  R0. By the convexity of g and the Cauchy-Schwartz inequality, we have
g(x(r)) - g(x)  g(x(r)), x(r) - x  g(x(r)) R0.

Combining with (31), we obtain

g(x(r))

-

g(x(r+1))



 R02

(g(x(r))

-

g(x))2.

Let (r) = g(x(r)) - g(x), we obtain

(r) - (r+1)



 R02

(r).

Then we have

1

1  (r)

1

(r+1)  (r) + R02 (r+1)  (r) + R02 .

7

Summarizing the inequalities, we get

1 (r+1)



1 (0)

+

 R02

(r

+

1)



 R02

(r

+

1),

which leads to

(r+1)

=

g(x(r+1))

-

g(x)



1 

R02 r+1

=

2(Pmax

+

2 ) R02 , Pmin r + 1

where 2 = min{KL2, ( k Lk)2}. This completes the proof.

Q.E.D.

Let us compare this bound with the bound derived in [4, Theorem 3.1] (replacing the denominator r + 8/K by r), which is

g(xr) - g(x)  4

Pmax

+

Pmax Pmin

K L2 Pmin

R2 .
r

(32)

In

our

new

bound,

besides

reducing

the

coefficient

from

4

to

2

and

removing

the

factor

,Pmax
Pmin

we

improve KL2 to min{KL2, ( k Lk)2}. Neither of the two bounds KL2 and ( k Lk)2 implies

the other: when L = Lk, k the new bound ( k Lk)2 is K times larger; when L = KLk, k or

L = L1 > L2 = * * * = LK = 0 the new bound is K times smaller. In fact, when L = KLk, k,

our new bound is K times better than the bound in [4] for either Pk = Lk or Pk = L. For example,

when

Pk

=

L, k,

the

bound

in

[4]

becomes

O(

KL r

),

while

our

bound

is

O(

L r

),

which

matches

GD

(listed in Table 1 below). Another advantage of the new bound ( k Lk)2 is that it does not increase

if we add an artificial block xK+1 and perform CGD for function g(x, xk+1) = g(x); in contrast,

the existing bound KL2 will increase to (K + 1)L2, even though the algorithm does not change at

all.

We have demonstrated that our bound can match GD in some cases, but can possibly be K times

worse

than

GD.

An

interesting question

is:

for general convex problems

can

we obtain an

O(

L r

)

bound for cyclic BCGD, matching the bound of GD? Removing the K-factor in (32) will lead to an

O(

L r

)

bound

for

conservative

stepsize

Pk

=

L

no

matter

how

large

Lk

and

L

are.

We

conjecture

that

an

O(

L r

)

bound

for

cyclic

BCGD

cannot

be

achieved

for

general

convex

problems.

That

being

said,

we point out that the iteration complexity of cyclic BCGD may depend on other intrinsic parameters

of the problem such as {Lk}k and, possibly, third order derivatives of g. Thus the question of finding

the

best

iteration

complexity

bound

of

the

form

O(h(K

)

L r

),

where

h(K )

is

a

function

of

K,

may

not be the right question to ask for BCD type algorithms.

4 Conclusion

In this paper, we provide new analysis and improved complexity bounds for cyclic BCD-type meth-

ods.

For

convex

quadratic problems,

we

show

that

the

bounds

are

O(

L r

),

which

is

independent

of

K (except for a mild log2(2K) factor) and is about Lmax/L + L/Lmin times worse than those

for GD/PG. By a simple example we show that it is not possible to obtain an iteration complexity

O(L/(Kr)) for cyclic BCPG. For illustration, the main results of this paper in several simple set-

tings are summarized in the table below. Note that different ratios of L over Lk can lead to quite

different comparison.

Lip-constant 1/Stepsize
GD Random BCGD Cyclic BCGD [4] Cyclic CGD, Cor 3.1 Cyclic BCGD (QP)

Table 1: Comparison of Various Iteration Complexity Results

Diagonal Hessian Li = L Pi = L
L/r L/r
KL/r KL/r log2(2K)L/r

Full Hessian Li = Large stepsize Pi =

L KL
K

N/A

L/(Kr)

K 2 L/r

KL/r

log2(2K)KL/r

Full

Hessian Li

=

L K

Small stepsize Pi = L

L/r

L/r

KL/r

L/r log2(2K)L/r

8

References
[1] J. R. Angelos, C. C. Cowen, and S. K. Narayan. Triangular truncation and finding the norm of a hadamard multiplier. Linear Algebra and its Applications, 170:117 - 135, 1992.
[2] A. Beck. On the convergence of alternating minimization with applications to iteratively reweighted least squares and decomposition schemes. SIAM Journal on Optimization, 25(1):185-209, 2015.
[3] A. Beck, E. Pauwels, and S. Sabach. The cyclic block coordinate gradient method for convex optimization problems. 2015. Preprint, available on arXiv:1502.03716v1.
[4] A. Beck and L. Tetruashvili. On the convergence of block coordinate descent type methods. SIAM Journal on Optimization, 23(4):2037-2060, 2013.
[5] D. P. Bertsekas. Nonlinear Programming, 2nd ed. Athena Scientific, Belmont, MA, 1999. [6] L. Grippo and M. Sciandrone. On the convergence of the block nonlinear Gauss-Seidel method
under convex constraints. Operations Research Letters, 26:127-136, 2000. [7] M. Hong, X. Wang, M. Razaviyayn, and Z.-Q. Luo. Iteration complexity analysis of block
coordinate descent methods. 2013. Preprint, available online arXiv:1310.6957. [8] Z. Lu and L. Xiao. On the complexity analysis of randomized block-coordinate descent meth-
ods. 2013. accepted by Mathematical Programming. [9] Z. Lu and L. Xiao. Randomized block coordinate non-monotone gradient method for a class
of nonlinear programming. 2013. Preprint. [10] Z.-Q. Luo and P. Tseng. On the convergence of the coordinate descent method for convex
differentiable minimization. Journal of Optimization Theory and Application, 72(1):7-35, 1992. [11] Y. Nesterov. Introductory lectures on convex optimization: A basic course. Springer, 2004. [12] Y. Nesterov. Efficiency of coordiate descent methods on huge-scale optimization problems. SIAM Journal on Optimization, 22(2):341-362, 2012. [13] J. Nutini, M. Schmidt, I. H. Laradji, M. Friedlander, and H. Koepke. Coordinate descent converges faster with the Gauss-Southwell rule than random selection. In the Proceeding of the 30th International Conference on Machine Learning (ICML), 2015. [14] M. J. D. Powell. On search directions for minimization algorithms. Mathematical Programming, 4:193-201, 1973. [15] M. Razaviyayn, M. Hong, and Z.-Q. Luo. A unified convergence analysis of block successive minimization methods for nonsmooth optimization. SIAM Journal on Optimization, 23(2):1126-1153, 2013. [16] M. Razaviyayn, M. Hong, Z.-Q. Luo, and J. S. Pang. Parallel successive convex approximation for nonsmooth nonconvex optimization. In the Proceedings of the Neural Information Processing (NIPS), 2014. [17] P. Richtarik and M. Takac. Iteration complexity of randomized block-coordinate descent methods for minimizing a composite function. Mathematical Programming, 144:1-38, 2014. [18] A. Saha and A. Tewari. On the nonasymptotic convergence of cyclic coordinate descent method. SIAM Journal on Optimization, 23(1):576-601, 2013. [19] P. Tseng. Convergence of a block coordinate descent method for nondifferentiable minimization. Journal of Optimization Theory and Applications, 103(9):475-494, 2001. [20] Y. Xu and W. Yin. A block coordinate descent method for regularized multiconvex optimization with applications to nonnegative tensor factorization and completion. SIAM Journal on Imaging Sciences, 6(3):1758-1789, 2013.
9

