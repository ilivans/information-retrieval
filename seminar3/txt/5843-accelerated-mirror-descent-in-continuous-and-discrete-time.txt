Accelerated Mirror Descent in Continuous and Discrete Time

Walid Krichene UC Berkeley
walid@eecs.berkeley.edu

Alexandre M. Bayen UC Berkeley
bayen@berkeley.edu

Peter L. Bartlett UC Berkeley and QUT
bartlett@berkeley.edu

Abstract
We study accelerated mirror descent dynamics in continuous and discrete time. Combining the original continuous-time motivation of mirror descent with a recent ODE interpretation of Nesterov's accelerated method, we propose a family of continuous-time descent dynamics for convex functions with Lipschitz gradients, such that the solution trajectories converge to the optimum at a O(1/t2) rate. We then show that a large family of first-order accelerated methods can be obtained as a discretization of the ODE, and these methods converge at a O(1/k2) rate. This connection between accelerated mirror descent and the ODE provides an intuitive approach to the design and analysis of accelerated first-order algorithms.
1 Introduction
We consider a convex optimization problem, minimizexX f (x), where X  Rn is convex and closed, f is a C1 convex function, and f is assumed to be Lf -Lipschitz. Let f be the minimum of f on X . Many convex optimization methods can be interpreted as the discretization of an ordinary differential equation, the solutions of which are guaranteed to converge to the set of minimizers. Perhaps the simplest such method is gradient descent, given by the iteration x(k+1) = x(k) -sf (x(k)) for some step size s, which can be interpreted as the discretization of the ODE X (t) = -f (X(t)), with discretization step s. The well-established theory of ordinary differential equations can provide guidance in the design and analysis of optimization algorithms, and has been used for unconstrained optimization [8, 7, 13], constrained optimization [27] and stochastic optimization [25]. In particular, proving convergence of the solution trajectories of an ODE can often be achieved using simple and elegant Lyapunov arguments. The ODE can then be carefully discretized to obtain an optimization algorithm for which the convergence rate can be analyzed by using an analogous Lyapunov argument in discrete time.
In this article, we focus on two families of first-order methods: Nesterov's accelerated method [22], and Nemirovski's mirror descent method [19]. First-order methods have become increasingly important for large-scale optimization problems that arise in machine learning applications. Nesterov's accelerated method [22] has been applied to many problems and extended in a number of ways, see for example [23, 20, 21, 4]. The mirror descent method also provides an important generalization of the gradient descent method to non-Euclidean geometries, as discussed in [19, 3], and has many applications in convex optimization [6, 5, 12, 15], as well as online learning [9, 11]. An intuitive understanding of these methods is of particular importance for the design and analysis of new algorithms. Although Nesterov's method has been notoriously hard to explain intuitively [14], progress has been made recently: in [28], Su et al. give an ODE interpretation of Nesterov's method. However, this interpretation is restricted to the original method [22], and does not apply to its extensions to non-Euclidean geometries. In [1], Allen-Zhu and Orecchia give another interpretation of Nesterov's method, as performing, at each iteration, a convex combination of a mirror step and a gradient step. Although it covers a broader family of algorithms (including non-Euclidean geometries), this interpretation still requires an involved analysis, and lacks the simplicity and elegance of
1

ODEs. We provide a new interpretation which has the benefits of both approaches: we show that a broad family of accelerated methods (which includes those studied in [28] and [1]) can be obtained as a discretization of a simple ODE, which converges at a O(1/t2) rate. This provides a unified interpretation, which could potentially simplify the design and analysis of first-order accelerated methods.

The continuous-time interpretation [28] of Nesterov's method and the continuous-time motivation

of mirror descent [19] both rely on a Lyapunov argument. They are reviewed in Section 2. By

combining these ideas, we propose, in Section 3, a candidate Lyapunov function V (X(t), Z(t), t) that depends on two state variables: X(t), which evolves in the primal space E = Rn, and Z(t), which evolves in the dual space E, and we design coupled dynamics of (X, Z) to guarantee that

d dt

V

(X

(t),

Z

(t),

t)



0.

Such a function is said to

be a Lyapunov function, in reference to [18];

see also [16]. This leads to a new family of ODE systems, given in Equation (5). We prove the

existence and uniqueness of the solution to (5) in Theorem 1. Then we prove in Thereom 2, using the Lyapunov function V , that the solution trajectories are such that f (X(t)) - f = O(1/t2). In

Section 4, we give a discretization of these continuous-time dynamics, and obtain a family of accelerated mirror descent methods, for which we prove the same O(1/k2) convergence rate (Theorem 3)

using a Lyapunov argument analogous to (though more involved than) the continuous-time case. We

give, as an example, a new accelerated method on the simplex, which can be viewed as performing,

at each step, a convex combination of two entropic projections with different step sizes. This ODE

interpretation of accelerated mirror descent gives new insights and allows us to extend recent results

such as the adaptive restarting heuristics proposed by O'Donoghue and Candes in [24], which are

known to empirically improve the convergence rate. We test these methods on numerical examples

in Section 5 and comment on their performance.

2 ODE interpretations of Nemirovski's mirror descent method and Nesterov's accelerated method

Proving convergence of the solution trajectories of an ODE often involves a Lyapunov argument. For

example, to prove convergence of the solutions to the gradient descent ODE X (t) = -f (X(t)),

consider

the

Lyapunov

function

V

(X (t))

=

1 2

X(t) - x

2 for some minimizer x . Then the time

derivative of V (X(t)) is given by

d V (X(t)) =

X (t), X(t) - x

= -f (X(t)), X(t) - x

 -(f (X(t)) - f ),

dt

where the last inequality is by convexity of f . Integrating, we have V (X(t)) - V (x0)  tf

t 0

f (X( ))d ,

thus

by

Jensen's

inequality,

f

1 t

t 0

X

(

)d

-f



1 t

t 0

f

(X

(

))d

-

f

- 

V

(x0 ) t

,

which

proves

that

f

1 t

t 0

X

(

)d

converges to f at a O(1/t) rate.

2.1 Mirror descent ODE

The previous argument was extended by Nemirovski and Yudin in [19] to a family of methods

called mirror descent. The idea is to start from a non-negative function V , then to design dynamics

for which V is a Lyapunov function. Nemirovski and Yudin argue that one can replace the Lyapunov

function V (X(t)) where Z(t)  E

=

1 2

X(t) - x

is a dual variable

2 by a function on the dual space, V (Z(t)) = D (Z(t), z for which we will design the dynamics (z is the value of Z

), at

equilibrium), and the corresponding trajectory in the primal space is X(t) = (Z(t)). Here  is

a convex function defined on E, such that  maps E to X , and D (Z(t), z ) is the Bregman divergence associated with , defined as D (z, y) = (z) - (y) - (y), z - y . The

function  is said to be -strongly convex w.r.t. a reference norm

*

 if D (z, y)  2

z-y

2 

for all y, z, and it is said to be L-smooth w.r.t.

*



if

D (z, y)



L 2

z-y

2 

.

For a review of

properties of Bregman divergences, see Chapter 11.2 in [11], or Appendix A in [2].

By definition of the Bregman divergence, we have

dd

V (Z(t)) dt

=

dt D (Z(t), z

) = d ((Z(t)) - (z dt

)-

(z), Z(t) - z

= (Z(t)) - (z ), Z (t) = X(t) - x , Z (t) .

)

2

Therefore, if the dual variable Z obeys the dynamics Z = -f (X), then

d V (Z(t)) = - f (X(t)), X(t) - x  -(f (X(t)) - f ) dt

and by the same argument as in the gradient descent ODE, V is a Lyapunov function and

f

1 t

t 0

X

(

)d

-f

converges to 0 at a O(1/t) rate. The mirror descent ODE system can be

summarized by

 

X = (Z)



Z = -f (X)

(1)

 

X(0) = x0, Z(0) = z0 with (z0) = x0

Note that since  maps into X , X(t) = (Z(t)) remains in X . Finally, the unconstrained

gradient descent ODE can be obtained as a special case of the mirror descent ODE (1) by taking

(z)

=

1 2

z

2, for which  is the identity, in which case X and Z coincide.

2.2 ODE interpretation of Nesterov's accelerated method

In [28], Su et al. show that Nesterov's accelerated method [22] can be interpreted as a discretization of a second-order differential equation, given by

X

+

r+1 t

X

+

f (X)

=

0

X(0) = x0, X (0) = 0

(2)

The

argument

uses

the

following

Lyapunov

function

(up

to

reparameterization),

E (t)

=

t2 r

(f

(X

)

-

f

)

+

r 2

X

+

t r

X

-

x

2, which is proved to be a Lyapunov function for the ODE (2) whenever

r  2. Since E is decreasing along trajectories of the system, it follows that for all t > 0, E(t) 

E(0) =

r 2

x0 - x

2, therefore f (X(t)) - f



r t2

E

(t)



r t2

E

(0)



r2 t2

x0 -x 2

2
, which proves

that f (X(t)) converges to f at a O(1/t2) rate. One should note in particular that the squared

Euclidean norm is used in the definition of E(t) and, as a consequence, discretizing the ODE (2)

leads to a family of unconstrained, Euclidean accelerated methods. In the next section, we show

that by combining this argument with Nemirovski's idea of using a general Bregman divergence

as a Lyapunov function, we can construct a much more general family of ODE systems which have the same O(1/t2) convergence guarantee. And by discretizing the resulting dynamics, we

obtain a general family of accelerated methods that are not restricted to the unconstrained Euclidean

geometry.

3 Continuous-time Accelerated Mirror Descent

3.1 Derivation of the accelerated mirror descent ODE

We consider a pair of dual convex functions,  defined on X and  defined on E, such that  : E  X . We assume that  is L -smooth with respect to * , a reference norm on the dual space. Consider the function

V (X(t), Z(t), t) =

t2 (f (X(t)) - f r

) + rD (Z(t), z

)

(3)

where Z is a dual variable for which we will design the dynamics, and z is its value at equilibrium.

Taking the time-derivative of V , we have

d V (X(t), Z(t), t) = 2t (f (X) - f

t2 )+

f (X), X

+r

Z , (Z) - (z ) .

dt r r

Assume that Z

=

-

t r

f

(X ).

Then,

the

time-derivative

of

V

becomes

d V (X(t), Z(t), t) = 2t (f (X) - f ) - t f (X), - t X + (Z) - (z ) .

dt r

r

Therefore, if Z

is such that (Z) = X

+

t r

X

,

and



(z

)=x

, then,

d V (X(t), Z(t), t) =

2t (f (X) - f

)-t

f (X), X - x



2t (f (X)

-

f

) - t(f (X) - f

)

dt r

r

 -t r - 2 (f (X) - f ) r

(4)

3

and it follows that V is a Lyapunov function whenever r  2. The proposed ODE system is then


 

X

=

r t

(

(Z

)

-

X ),

Z

=

-

t r

f

(X

),

 

X(0) = x0, Z(0) = z0, with (z0) = x0.

(5)

In the unconstrained Euclidean case, taking (z)

=

1 2

z

2, we have (z)

=

z, thus Z

=

X

+

t r

X

,

and

the

ODE

system

is

equivalent

to

d dt

X

+

t r

X

=

-

t r

f

(X ),

which

is

equivalent

to

the ODE (2) studied in [28], which we recover as a special case.

We also give another interpretation of ODE (5): the first equation is equivalent to trX + rtr-1X =

rtr-1(Z), or, in integral form, trX(t) =

r

t 0

 r-1(Z( ))d ,

which

can

be

written

as

X(t) =

t 0

w(

)  (Z (

t 0

w(

)d

))d

,

with w( )

=

 r-1.

Therefore the coupled dynamics of (X, Z)

can

be interpreted variable X is

as a

follows: the dual variable Z accumulates gradients weighted average of (Z( )) (the "mirrored"

with dual

a

t r

rate,

while

the

primal

trajectory), with weights

proportional to  r-1. This also gives an interpretation of r as a parameter controlling the weight

distribution. It is also interesting to observe that the weights are increasing if and only if r  2.

Finally, with this averaging interpretation, it becomes clear that the primal trajectory X(t) remains

in X , since  maps into X and X is convex.

3.2 Solution of the proposed dynamics

First, we prove existence and uniqueness of a solution to the ODE system (5), defined for all t >

0. By assumption,  is L -smooth w.r.t. * , which is equivalent (see e.g. [26]) to  is

L -Lipschitz.

Unfortunately,

due

to

the

r t

term

in

the

expression

of

X ,

the

function

(X, Z, t)



(X , Z ) is not Lipschitz at t = 0, and we cannot directly apply the Cauchy-Lipschitz existence and

uniqueness theorem. However, one can work around it by considering a sequence of approximating

ODEs, similarly to the argument used in [28].

Theorem 1. Suppose f is C1, and that f is Lf -Lipschitz, and let (x0, z0)  X x E such that (z0) = x0. Then the accelerated mirror descent ODE system (5) with initial condition (x0, z0) has a unique solution (X, Z), in C1([0, ), Rn).

We will show existence of a solution on any given interval [0, T ] (uniqueness is proved in the supplementary material). Let  > 0, and consider the smoothed ODE system


 

X

=

r max(t,)

(

(Z

)

-

X ),

Z

=

-

t r

f

(X

),

 

X(0) = x0, Z(0) = z0 with (z0) = x0.

(6)

Since

the

functions

(X, Z)



-

t r

f

(X

)

and

(X, Z)



r max(t,)

(

(Z

)

-

X)

are

Lipschitz

for

all t  [0, T ], by the Cauchy-Lipschitz theorem (Theorem 2.5 in [29]), the system (6) has a unique

solution (X, Z) in C1([0, T ]). In order to show the existence of a solution to the original ODE,

we use the following Lemma (proved in the supplementary material).

Lemma 1.

Let t0

=

2 .
Lf L

Then the family of solutions

(X, Z)|[0,t0] t0 is equi-Lipschitz-

continuous and uniformly bounded.

Proof of existence. Consider the family of solutions (Xi , Zi ), i = t02-i iN restricted to [0, t0]. By Lemma 1, this family is equi-Lipschitz-continuous and uniformly bounded, thus by the Arzela-

Ascoli theorem, there exists a subsequence ((Xi , Zi ))iI that converges uniformly on [0, t0] (where I  N is an infinite set of indices). Let (X , Z) be its limit. Then we prove that (X , Z) is a solution to the original ODE (5) on [0, t0].

First, since limi,iI

for all i Xi (0) =

 I, x0 and

ZX(0i)(0=)

= x0 and Zi (0) limi,iI Zi (0) =

= z0,

z0, thus

it follows that (X , Z) satisfies

X (0) = the initial

cinointidailticoonnsd. itNioenxt(,Xle(tt1t)1,

 Z

(0, t0 (t1)).

), and Since

let (X , Z) be the solution of the (Xi (t1), Zi (t1))iI  (X (t1),

ODE (5) Z(t1)) as

on t i

 t1, with , then by

4

continuity of the solution w.r.t. initial conditions (Theorem 2.8 in [29]), we have that for some > 0, Xi  X uniformly on [t1, t1 + ). But we also have Xi  X uniformly on [0, t0], therefore X and X coincide on [t1, t1 + ), therefore X satisfies the ODE on [t1, t1 + ). And since t1 is arbitrary in (0, t0), this concludes the proof of existence.

3.3 Convergence rate

It is now straightforward to establish the convergence rate of the solution.

Theorem 2. Suppose that f has Lipschitz gradient, and that  is a smooth distance generating

function. Let (X(t), Z(t)) be the solution to the accelerated mirror descent ODE (5) with r  2.

Then for all t > 0, f (X(t)) - f



r2D (z0,z t2

).

Proof.

By construction of the ODE, V (X(t), Z(t), t)

=

t2 r

(f

(X (t))

-

f

) + rD (Z(t), z

) is

a Lyapunov function.

It

follows

that

for

all

t

>

0,

t2 r

(f (X(t))

-

f

)  V (X(t), Z(t), t) 

V (x0, z0, 0) = rD (z0, z ).

4 Discretization

Next, we show that with a careful discretization of this continuous-time dynamics, we can obtain a

general family of accelerated mirror descent methods for constrained optimization. Using a mixed

forward/backward Euler scheme (see e.g. Chapter 2 in [10]), we can

using a step X(tk) = X

(skizes).sAapspfroolxloimwsa.tiGngivXen(taks)owluittihonX((Xtk+, Z)ss)o-fXth(tek

ODE ) , we

discretize (5), let tk

t=hekODsE, asnydstxem(k)(5=)

propose the discretization

x(k+1) -x(k) s
z (k+1) -z (k) s

= +

kkrrssf (x(k(+z(1k))))=-0x.(k+1)

,

(7)

The first equation can be rewritten as x(k+1) =

x(k)

+

r k



(z

(k))

/

1

+

r k

(note the indepen-

dence on s, due to the time-scale invariance of the first ODE). In other words, x(k+1) is a convex

combination

of

(z(k))

and

x(k)

with

coefficients

k

=

r r+k

and

1

-

k

=

k r+k

.

To

summarize,

our first discrete scheme can be written as

x(k+1)

=

k(z(k)) + (1 - k)x(k),

k

=

r r+k

,

z(k+1)

=

z(k)

-

ks r

f

(x(k+1)

).

(8)

Since  maps into the feasible set X , starting from x(0)  X guarantees that x(k) remains in X for all k (by convexity of X ). Note that by duality, we have (x) = arg maxxX x, x -(x), and if we additionally assume that  is differentiable on the image of , then  = ()-1 (Theorem 23.5 in [26]), thus if we write z(k) = (z(k)), the second equation can be written as

z(k+1) = ((z(k)) - ks f (x(k+1))) = arg min (x) - r xX

ks = arg min
xX r

f (x(k+1)), x

+ D(x, z(k)).

(z(k)) - ks f (x(k+1)), x r

We will eventually modify this scheme in order to be able to prove the desired O(1/k2) convergence

rate. However, we start by analyzing this

function (3), V (x(k), z(k),

kandsu) s=ingkr2tsh(efc(oxr(rke)s)p-onfde)nc+e

vtersiokn. sM, woteivcaotendsibdyer

the the

continuous-time Lyapunov potential function E(k) =

rD (z(k), z ). Then we have

E(k+1) - E(k) = (k + 1)2s (f (x(k+1)) - f r

) - k2s (f (x(k)) - f r

) + r(D (z(k+1), z

) - D (z(k), z

))

=

k2s (f (x(k+1)) - f (x(k))) + s(1 + 2k) (f (x(k+1)) - f rr

) + r(D (z(k+1), z

) - D (z(k), z

)).

5

And through simple algebraic manipulation, the last term can be bounded as follows

D (z(k+1), z ) - D (z(k), z ) = D (z(k+1), z(k)) + (z(k)) - (z ), z(k+1) - z(k)

by definition of the Bregman divergence

= D (z(k+1), z(k)) +

k (x(k+1) - x(k)) + x(k+1) - x , - ks f (x(k+1)) rr

by the discretization (8)



D (z(k+1), z(k))

+

k2s (f (x(k)) r2

-

f (x(k+1)))

+

ks (f r

- f (x(k+1))).

by convexity of f

Therefore

we

have

E (k+1)

-

E (k)



-

s[(r-2)k-1] r

(f

(x(k+1))

-

f

) + rD (z(k+1), z(k)). Com-

paring

this

expression

with

the

expression

(4)

of

d dt

V

(X

(t),

Z

(t),

t)

in

the

continuous-time

case,

we see that we obtain an analogous expression, except for the additional Bregman divergence term

rD (z(k+1), z(k)), and we cannot immediately conclude that V is a Lyapunov function. This can

be remedied by the following modification of the discretization scheme.

4.1 A family of discrete-time accelerated mirror descent methods

In the expression (8) of x(k+1) = kz(k) + (1 - k)x(k), we propose to replace x(k) with x(k), ob-

tained as a solution to a minimization problem x(k) = arg minxX s f (x(k)), x + R(x, x(k)),

where R is regularization function that satisfies the following assumptions: there exist 0 < R  LR

such that for all x, x  X ,

R
2

x-x

2



R(x, x

)



LR 2

x-x

2.

In the Euclidean case, one can take R(x, x ) =

x-x 2

2
, in which case

R = LR = 1 and the

x update becomes a prox-update. In the general case, one can take R(x, x ) = D(x, x ) for

some distance generating function  which is R-strongly convex and LR-smooth, in which case

the x update becomes a mirror update. The resulting method is summarized in Algorithm 1. This

algorithm is a generalization of Allen-Zhu and Orecchia's interpretation of Nesterov's method in [1],

where x(k+1) is a convex combination of a mirror descent update and a gradient descent update.

Algorithm 1 Accelerated mirror descent with distance generating function , regularizer R, step size s, and parameter r  3

1: Initialize x(0) = x0, z(0) = x0, or z(0)  ()-1(x0) .

2: for k  N do

3:

x(k+1)

=

k z(k)

+ (1

-

k )x(k) ,

with

k

=

r r+k

.

4:

z(k+1)

= arg minzX

ks r

f (x(k+1)), z

+ D(z, z(k)).

If



is

non-differentiable,

z(k+1)

=

z(k)

-

kr s

f

(x(k+1) )

and

z(k+1)

=

(z(k+1)).

5: x(k+1) = arg minxX s f (x(k+1)), x + R(x, x(k+1))

4.2 Consistency of the modified scheme

One can show that given our assumptions on R, x(k) = x(k) + O(s). Indeed, we have

R x(k) - x(k) 2  R(x(k), x(k))  R(x(k), x(k)) + s f (x(k)), x(k) - x(k) 2
 s f (x(k))  x(k) - x(k)

therefore x(k) - x(k)  s 2 f(x(k))  , which proves the claim. Using this observation, we R
can show that the modified discretization scheme is consistent with the original ODE (5), that is, the difference equations defining x(k) and z(k) converge, as s tends to 0, to the ordinary differential
equations of the continuous-time system (5). The difference equations of Algorithm 1 are equivalent to (7) in which x(k) is replaced by x(k), i.e.

x(k+1) -x(k) s
z (k+1) -z (k) s

= kr s((z(k)) -

=

-

k r

s f (x(k+1))

x(k+1))

6

Now suppose there exist C1

Z(tk)  z(k) for tk = k

= +x(k+1)-x(k)
s

x(k+1) -x(k) s

functions (X, Z), defined

Os(.s)Then,Xu(tski+ngsts)h-eX

fact
(tk )

on R+, such that x(k) = + O( s) =

that X(tk)  x(k) + O(s),
X (tk) + o(1),

x(k) and we have
and simi-

larly,

z (k+1) -z (k) s



Z (tk) + o(1), therefore the difference equation system can be written as

X (tk) + o(1) Z (tk) + o(1)

= =

-trktr(kf((XZ((ttkk

)) +

- X(tk s))

+

 s))

which converges to the ODE (5) as s  0.

4.3 Convergence rate

To prove convergence of the algorithm, consider the modified potential function

E(k) = V (x(k), z(k), ks) =

k2s r

(f

(x(k))

-

f

) + rD (z(k), z

).

Lemma 2.

If 

 LRL

and s 

R
2Lf 

,

then

for

all

k

 0,

E (k+1)

-

E (k)



(2k

+

1- r

kr)s (f (x(k+1))

-

f

).

As a consequence, if r  3, E is a Lyapunov function for k  1. This lemma is proved in the supplementary material.

Theorem 3. The discrete-time accelerated mirror descent Algorithm 1 with parameter r  3 and

step

sizes





LRL ,

s



R
2Lf



,

guarantees

that

for

all

k

>

0,

f (x(k))) - f



r sk2

E (1)



r2D (z0, z sk2

)

+

f (x0) - f k2

.

Proof. The first inequality follows immediately from Lemma 2. The second inequality follows from a simple bound on E(1), proved in the supplementary material.

4.4 Example: accelerated entropic descent

We give an instance of Algorithm 1 for simplex-constrained problems. Suppose that X = n =

{x  Rn+ x  X, z

: 

n
Ei=, 1

xi

=

1}

is

the

n-simplex.

Taking



to

be

the

negative

entropy

on

,

we

have

for

nn

(x) = xi ln xi+(x|), (z) = ln

ezi , (x) = (1 + ln xi)i+Ru, (z)i =

i=1

i=1

ezi

n j=1

ezj

.

where (*|) is the indicator function of the simplex ((x|) = 0 if x   and + otherwise), and u  Rn is a normal vector to the affine hull of the simplex. The resulting mirror descent update is a simple entropy projection and can be computed exactly in O(n) operations, and 
can be shown to be 1-smooth w.r.t. * , see for example [3, 6]. For the second update, we tleaexktpereR>ss(ix0o,n, yains)dk=nleotwDn(fx(ox)r,=y)w,hitenic=rea1n(xbieis+coam)spmlnuot(eoxdtihe+efdficn)iee+gnatltyi(v,xein|eOn)t.(rnAopllotyhgofnuu)ngcthitminoeonusdsimienfipgnlaee,ddcealtosesrfmeodil-nlfoiowsrtmisc:
algorithm, or O(n) expected time using a randomized algorithm, see [17]. Additionally,  satisfies
our assumptions: it is 1+n -strongly convex and 1-smooth w.r.t. * . The resulting accelerated mirror descent method on the simplex can then be implemented efficiently, and by Theorem 3 it is guaranteed to converge in O(1/k2) whenever   1 and s  2(1+n )Lf  .

5 Numerical Experiments

We test the accelerated mirror descent method in Algorithm 1, on simplex-constrained problems in Rn, n = 100, with two different objective functions: a simple quadratic f (x) = x - x , Q(x - x ) , for a random positive semi-definite matrix Q, and a log-sum-exp function

7

f (x(k)) - f f (x(k)) - f f (x(k)) - f

10-1

10-5

10-9

10-13 10-17

Mirror descent Accelerated mirror descent Speed restart Gradient restart
100 200 300 400 500 600 700 k

(a) Weakly convex quadratic, rank 10

10-2 10-5 10-8 10-11 10-14

Mirror descent Accelerated mirror descent Speed restart Gradient restart
100 200 300 400 k

500

(b) Log-sum-exp

600

10-2 10-5

r=3 r = 10 r = 30 r = 90

10-8

10-11

10-14

10-17

100 200 300 400 500 600 700 800 k

(c) Effect of the parameter r.

Figure 1: Evolution of f (x(k)) - f on simplex-constrained problems, using different accelerated mirror descent methods with entropy distance generating functions.

Algorithm 2 Accelerated mirror descent with restart

1: Initialize l = 0, x(0) = z(0) = x0.

2: for k  N do

3:

x(k+1)

=

lz(k)

+

(1

-

l)x(k),

with

l

=

r r+l

4:

z(k+1)

= arg minzX

ks r

f (x(k+1)), z

+ D(z, z(k))

5: x(k+1) = arg minxX s f (x(k+1)), x + R(x, x(k+1))
6: l  l + 1 7: if Restart condition then 8: z(k+1)  x(k+1), l  0

given by f (x) = ln

I i=1

ai, x

+ bi

, where each entry in ai



Rn and bi



R is iid nor-

mal. We implement the accelerated entropic descent algorithm proposed in Section 4.4, and in-

clude the (non-accelerated) entropic descent for reference. We also adapt the gradient restarting

heuristic proposed by O'Donoghue and Candes in [24], as well as the speed restart heuristic pro-

posed by Su et al. in [28]. The generic restart method is given in Algorithm 2. The restart condi-

tions are the following: (i) gradient restart: x(k+1) - x(k), f (x(k)) > 0, and (ii) speed restart:

x(k+1) - x(k) < x(k) - x(k-1) .

The results are given in Figure 1. The accelerated mirror descent method exhibits a polynomial convergence rate, which is empirically faster than the O(1/k2) rate predicted by Theorem 3. The method also exhibits oscillations around the set of minimizers, and increasing the parameter r seems
to reduce the period of the oscillations, and results in a trajectory that is initially slower, but faster for large k, see Figure 1-c. The restarting heuristics alleviate the oscillation and empirically speed up the convergence. We also visualized, for each experiment, the trajectory of the iterates x(k) for each method, projected on a 2-dimensional hyperplane. The corresponding videos are included in
the supplementary material.

6 Conclusion

By combining the Lyapunov argument that motivated mirror descent, and the recent ODE interpretation [28] of Nesterov's method, we proposed a family of ODE systems for minimizing convex functions with a Lipschitz gradient, which are guaranteed to converge at a O(1/t2) rate, and proved existence and uniqueness of a solution. Then by discretizing the ODE, we proposed a family of accelerated mirror descent methods for constrained optimization and proved an analogous O(1/k2) rate when the step size is small enough. The connection with the continuous-time dynamics motivates a more detailed study of the ODE (5), such as studying the oscillatory behavior of its solution trajectories, its convergence rates under additional assumptions such as strong convexity, and a rigorous study of the restart heuristics.
Acknowledgments
We gratefully acknowledge the NSF (CCF-1115788, CNS-1238959, CNS-1238962, CNS-1239054, CNS-1239166), the ARC (FL110100281 and ACEMS), and the Simons Institute Fall 2014 Algorithmic Spectral Graph Theory Program.

8

References
[1] Zeyuan Allen-Zhu and Lorenzo Orecchia. Linear coupling: An ultimate unification of gradient and mirror descent. In ArXiv, 2014.
[2] Arindam Banerjee, Srujana Merugu, Inderjit S. Dhillon, and Joydeep Ghosh. Clustering with Bregman divergences. J. Mach. Learn. Res., 6:1705-1749, December 2005.
[3] Amir Beck and Marc Teboulle. Mirror descent and nonlinear projected subgradient methods for convex optimization. Oper. Res. Lett., 31(3):167-175, May 2003.
[4] Amir Beck and Marc Teboulle. A fast iterative shrinkage-thresholding algorithm for linear inverse problems. SIAM Journal on Imaging Sciences, 2(1):183-202, 2009.
[5] A. Ben-Tal and A. Nemirovski. Lectures on Modern Convex Optimization. SIAM, 2001.
[6] Aharon Ben-Tal, Tamar Margalit, and Arkadi Nemirovski. The ordered subsets mirror descent optimization method with applications to tomography. SIAM J. on Optimization, 12(1):79-108, January 2001.
[7] Anthony Bloch, editor. Hamiltonian and gradient flows, algorithms, and control. American Mathematical Society, 1994.
[8] A. A. Brown and M. C. Bartholomew-Biggs. Some effective methods for unconstrained optimization based on the solution of systems of ordinary differential equations. Journal of Optimization Theory and Applications, 62(2):211-224, 1989.
[9] Sebastien Bubeck and Nicolo Cesa-Bianchi. Regret analysis of stochastic and nonstochastic multi-armed bandit problems. Foundations and Trends in Machine Learning, 5(1):1-122, 2012.
[10] J. C. Butcher. Numerical Methods for Ordinary Differential Equations. John Wiley & Sons, Ltd, 2008.
[11] Nicolo Cesa-Bianchi and Gabor Lugosi. Prediction, Learning, and Games. Cambridge, 2006.
[12] Ofer Dekel, Ran Gilad-Bachrach, Ohad Shamir, and Lin Xiao. Optimal distributed online prediction. In Proceedings of the 28th International Conference on Machine Learning (ICML), June 2011.
[13] U. Helmke and J.B. Moore. Optimization and dynamical systems. Communications and control engineering series. Springer-Verlag, 1994.
[14] Anatoli Juditsky. Convex Optimization II: Algorithms, Lecture Notes. 2013.
[15] Anatoli Juditsky, Arkadi Nemirovski, and Claire Tauvel. Solving variational inequalities with stochastic mirror-prox algorithm. Stoch. Syst., 1(1):17-58, 2011.
[16] H.K. Khalil. Nonlinear systems. Macmillan Pub. Co., 1992.
[17] Walid Krichene, Syrine Krichene, and Alexandre Bayen. Efficient Bregman projections onto the simplex. In 54th IEEE Conference on Decision and Control, 2015.
[18] A.M. Lyapunov. General Problem of the Stability Of Motion. Control Theory and Applications Series. Taylor & Francis, 1992.
[19] A. S. Nemirovsky and D. B. Yudin. Problem Complexity and Method Efficiency in Optimization. WileyInterscience series in discrete mathematics. Wiley, 1983.
[20] Yu. Nesterov. Smooth minimization of non-smooth functions. Mathematical Programming, 103(1):127- 152, 2005.
[21] Yu. Nesterov. Gradient methods for minimizing composite functions. Mathematical Programming, 140(1):125-161, 2013.
[22] Yurii Nesterov. A method of solving a convex programming problem with convergence rate o(1/k2). Soviet Mathematics Doklady, 27(2):372-376, 1983.
[23] Yurii Nesterov. Introductory Lectures on Convex Optimization, volume 87. Springer Science & Business Media, 2004.
[24] Brendan O'Donoghue and Emmanuel Candes. Adaptive restart for accelerated gradient schemes. Foundations of Computational Mathematics, 15(3):715-732, 2015.
[25] M. Raginsky and J. Bouvrie. Continuous-time stochastic mirror descent on a network: Variance reduction, consensus, convergence. In CDC 2012, pages 6793-6800, 2012.
[26] R.T. Rockafellar. Convex Analysis. Princeton University Press, 1970.
[27] J. Schropp and I. Singer. A dynamical systems approach to constrained minimization. Numerical Functional Analysis and Optimization, 21(3-4):537-551, 2000.
[28] Weijie Su, Stephen Boyd, and Emmanuel Candes. A differential equation for modeling Nesterov's accelerated gradient method: Theory and insights. In NIPS, 2014.
[29] Gerald Teschl. Ordinary differential equations and dynamical systems, volume 140. American Mathematical Soc., 2012.
9

